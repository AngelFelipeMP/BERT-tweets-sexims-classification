{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"BertEnglish Task1 TrainOriginalEnglishData.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U94-LXc92z44"},"source":["# Downloading Dependences"]},{"cell_type":"code","metadata":{"id":"ELwqFdCntJfH"},"source":["# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcnNlFEcvTw0"},"source":["# !apt-get install git-lfs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4HXbKnk1fO_b"},"source":["# !git lfs install\n","# !git clone https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTcmKtj661jT"},"source":["# !git lfs install\n","# !git clone https://huggingface.co/bert-base-uncased"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cEv-emIkgeLm"},"source":["# !git lfs install\n","# !git clone https://huggingface.co/bert-base-multilingual-uncased"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VK_nUhVyxjWy"},"source":["# !pip install transformers==3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tjFmFhWd2hq1"},"source":["# Load Dependences"]},{"cell_type":"code","metadata":{"id":"8EGoAnTU2BNc"},"source":["### add NLP dependences\n","import pickle\n","import os\n","import torch\n","import pandas as pd\n","from scipy import stats\n","import numpy as np\n","import os\n","\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","\n","from tqdm import tqdm\n","from collections import OrderedDict, namedtuple\n","import torch.nn as nn\n","from torch.optim import lr_scheduler\n","import joblib\n","\n","import logging\n","import transformers\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n","import sys\n","from sklearn import metrics, model_selection\n","\n","import warnings\n","import torch_xla\n","import torch_xla.debug.metrics as met\n","import torch_xla.distributed.data_parallel as dp\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.utils.utils as xu\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","import torch_xla.test.test_utils as test_utils\n","import warnings\n","\n","from torch_xla.core.xla_model import mesh_reduce\n","\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOH2Op99s4XU","executionInfo":{"status":"ok","timestamp":1619288231193,"user_tz":180,"elapsed":19642,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"7f6977c1-7723-4ed0-ddae-9853d664aa09"},"source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT)           # we mount the google drive at /content/drive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jd3akA1t3l_R"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"pz-cjmTkHXGE"},"source":["class BERTBaseUncased(nn.Module):\n","    def __init__(self, bert_path, output_bert='pooler', NumberOfClasses=2):\n","        super(BERTBaseUncased, self).__init__()\n","        self.bert_path = bert_path\n","        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n","        self.bert_drop = nn.Dropout(0.3)\n","        self.output_bert = output_bert\n","        self.NumberOfClasses = NumberOfClasses\n","        self.OutPutHidden = nn.Linear(768 * 2, NumberOfClasses)\n","        self.OutPoller = nn.Linear(768, NumberOfClasses)\n","\n","    def forward(\n","            self,\n","            ids,\n","            mask,\n","            token_type_ids\n","    ):\n","        o1, o2 = self.bert(\n","            ids,\n","            attention_mask=mask,\n","            token_type_ids=token_type_ids)\n","          \n","        if self.output_bert=='hidden':\n","          apool = torch.mean(o1, 1)\n","          mpool, _ = torch.max(o1, 1)\n","          cat = torch.cat((apool, mpool), 1)\n","          bo = self.bert_drop(cat)\n","\n","          output = self.OutPutHidden(bo) \n","\n","        else:\n","          bo = self.bert_drop(o2)\n","          output = self.OutPoller(bo)\n","        \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bu6iEzVwmGi"},"source":["class BERTDatasetTraining:\n","    def __init__(self, comment, targets, tokenizer, max_length):\n","        self.comment = comment\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.comment)\n","\n","    def __getitem__(self, item):\n","        comment = str(self.comment[item])\n","        comment = \" \".join(comment.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment,\n","            None,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","        )\n","        ids = inputs[\"input_ids\"]\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        \n","        padding_length = self.max_length - len(ids)\n","        \n","        ids = ids + ([0] * padding_length)\n","        mask = mask + ([0] * padding_length)\n","        token_type_ids = token_type_ids + ([0] * padding_length)\n","        \n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[item], dtype=torch.float)\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLmqHi5aPf7b"},"source":["class TrainModel():\n","  def __init__(self, PathSaveFiles, BertVersion, BertPath,  OutputBert, LearningRate, BatchSize, Epochs, FileName, X_train, X_valid, y_train ,y_valid, MaxLen = 110, SaveModel=False):\n","    self.BertVersion = BertVersion\n","    self.BertPath = BertPath\n","    self.OutputBert = OutputBert\n","    self.LearningRate = LearningRate\n","    self.BatchSize = BatchSize\n","    self.Epochs = Epochs\n","    self.FileName = FileName\n","    self.X_train = X_train\n","    self.X_valid = X_valid\n","    self.y_train = y_train\n","    self.y_valid = y_valid\n","    self.NumberOfLabels = y_train.nunique()\n","    self.average_metrics =  'macro' if self.NumberOfLabels > 2 else 'binary'\n","    self.PathSaveFiles = PathSaveFiles\n","    self.MaxLen = MaxLen\n","    self.SaveModel = SaveModel\n","\n","\n","  def _run(self):\n","      def OpenEndSave(CurrentEpoch, module):\n","          if module == 'open'and CurrentEpoch == 1:\n","            with open(self.PathSaveFiles + self.FileName + \".pkl\", \"rb\") as f:\n","              self.Results = pickle.load(f)\n","\n","          elif module == 'save' and CurrentEpoch == self.Epochs:\n","            with open(self.PathSaveFiles + self.FileName + \".pkl\",'wb') as f:\n","              pickle.dump(self.Results, f)\n","\n","\n","      def loss_fn(outputs, targets):\n","        return nn.CrossEntropyLoss()(outputs, targets)\n","            \n","\n","      def train_loop_fn(data_loader, model, optimizer, device, scheduler=None, epoch=None):\n","          model.train()\n","          for bi, d in enumerate(data_loader):\n","              ids = d[\"ids\"]\n","              mask = d[\"mask\"]\n","              token_type_ids = d[\"token_type_ids\"]\n","              targets = d[\"targets\"]\n","\n","              ids = ids.to(device, dtype=torch.long)\n","              mask = mask.to(device, dtype=torch.long)\n","              token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","              targets = targets.to(device, dtype=torch.float)\n","              \n","\n","              optimizer.zero_grad()\n","              outputs = model(\n","                  ids=ids,\n","                  mask=mask,\n","                  token_type_ids=token_type_ids\n","              )\n","\n","              loss = loss_fn(outputs, targets)\n","              if bi % 10 == 0:\n","                  xm.master_print(f'bi={bi}, loss={loss}')\n","\n","                  ValueLoss = loss.cpu().detach().numpy().tolist()\n","                  ValueLoss = xm.mesh_reduce('test_loss',ValueLoss, np.mean)\n","                  self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['loss'].append(ValueLoss)\n","\n","              loss.backward()\n","              xm.optimizer_step(optimizer)\n","              if scheduler is not None:\n","                  scheduler.step()\n","\n","      def eval_loop_fn(data_loader, model, device):\n","          model.eval()\n","          fin_targets = []\n","          fin_outputs = []\n","          for bi, d in enumerate(data_loader):\n","              ids = d[\"ids\"]\n","              mask = d[\"mask\"]\n","              token_type_ids = d[\"token_type_ids\"]\n","              targets = d[\"targets\"]\n","\n","              ids = ids.to(device, dtype=torch.long)\n","              mask = mask.to(device, dtype=torch.long)\n","              token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","              targets = targets.to(device, dtype=torch.float)\n","\n","              outputs = model(\n","                  ids=ids,\n","                  mask=mask,\n","                  token_type_ids=token_type_ids\n","              )\n","\n","              targets_np = targets.cpu().detach().numpy().tolist()\n","              outputs = torch.argmax(outputs, dim=1)\n","              outputs_np = outputs.detach().cpu().numpy().tolist()\n","\n","              fin_targets.extend(targets_np)\n","              fin_outputs.extend(outputs_np)    \n","\n","          return fin_outputs, fin_targets\n","\n","      # tokenizer\n","      tokenizer = transformers.BertTokenizer.from_pretrained(self.BertPath, do_lower_case=True)\n","\n","      train_dataset = BERTDatasetTraining(\n","          comment=self.X_train.values,\n","          targets=self.y_train.values,\n","          tokenizer=tokenizer,\n","          max_length=self.MaxLen\n","      )\n","\n","      train_sampler = torch.utils.data.distributed.DistributedSampler(\n","            train_dataset,\n","            num_replicas=xm.xrt_world_size(),\n","            rank=xm.get_ordinal(),\n","            shuffle=True)\n","\n","      train_data_loader = torch.utils.data.DataLoader(\n","          train_dataset,\n","          batch_size=self.BatchSize,\n","          sampler=train_sampler,\n","          drop_last=True,\n","          num_workers=1\n","      )\n","\n","      valid_dataset = BERTDatasetTraining(\n","          comment=self.X_valid.values,\n","          targets=self.y_valid.values,\n","          tokenizer=tokenizer,\n","          max_length=self.MaxLen\n","      )\n","\n","      valid_sampler = torch.utils.data.distributed.DistributedSampler(\n","            valid_dataset,\n","            num_replicas=xm.xrt_world_size(),\n","            rank=xm.get_ordinal(),\n","            shuffle=False)\n","\n","      valid_data_loader = torch.utils.data.DataLoader(\n","          valid_dataset,\n","          batch_size=16,\n","          sampler=valid_sampler,\n","          drop_last=False,\n","          num_workers=1\n","      )\n","\n","      device = xm.xla_device()\n","      model = mx.to(device)\n","      \n","\n","      param_optimizer = list(model.named_parameters())\n","      no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","      optimizer_grouped_parameters = [\n","          {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","          {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","\n","      \n","      lr = 0.4 * self.LearningRate * xm.xrt_world_size()\n","      num_train_steps = int(len(train_dataset) / self.BatchSize / xm.xrt_world_size() * self.Epochs)\n","      xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n","\n","      optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","      scheduler = get_linear_schedule_with_warmup(\n","          optimizer,\n","          num_warmup_steps=0,\n","          num_training_steps=num_train_steps\n","      )\n","\n","      best_f1, f1, best_cem, cem = 0,0,0,0\n","\n","      for epoch in range(1, self.Epochs+1):\n","        ## print epoch\n","          xm.master_print(f'Epoch: {epoch} of {self.Epochs}')\n","        ## Open file to save results\n","          OpenEndSave(CurrentEpoch=epoch, module='open')\n","\n","          para_loader = pl.ParallelLoader(train_data_loader, [device])\n","          train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler, epoch=epoch)\n","\n","          para_loader = pl.ParallelLoader(valid_data_loader, [device])\n","          o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n","          \n","          if self.NumberOfLabels == 2:\n","            f1 = xm.mesh_reduce('validation_f1', metrics.f1_score(t, o), np.mean)\n","            self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['f1'].append(f1)\n","\n","          else:\n","            self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['f1_macro'].append(xm.mesh_reduce('validation_f1_macro', metrics.f1_score(t, o, average=self.average_metrics), np.mean))\n","            self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['f1_weighted'].append(xm.mesh_reduce('validation_f1_weighted', metrics.f1_score(t, o, average='weighted'), np.mean))\n","            # cem = xm.mesh_reduce('validation_cem', cem_metric(t, o), np.mean)\n","            # self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['cem'].append(xm.mesh_reduce('validation_cem', cem_metric(t, o), np.mean))\n","\n","          accuracy = metrics.accuracy_score(t, o)\n","          accuracy = xm.mesh_reduce('test_accuracy', accuracy, np.mean)\n","          self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['accuracy'].append(accuracy)\n","          self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['recall'].append(xm.mesh_reduce('validation_recall', metrics.recall_score(t, o, average=self.average_metrics), np.mean))\n","          self.Results[self.BertVersion][self.OutputBert][self.LearningRate][self.BatchSize][epoch]['precision'].append(xm.mesh_reduce('validation_precison', metrics.precision_score(t, o, average=self.average_metrics), np.mean))\n","              \n","        ## save file with save results\n","          OpenEndSave(CurrentEpoch=epoch, module='save')\n","\n","        ## Save model\n","          if self.SaveModel and epoch == self.Epochs:\n","            xm.save(model.state_dict(), self.PathSaveFiles + self.FileName + '.bin')\n","        \n","        ## print accuracy\n","          xm.master_print(f'Accuracy = {accuracy}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yzvib7kT2Ku6"},"source":["#Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"jcX788LwMQ1j","executionInfo":{"status":"ok","timestamp":1619288252322,"user_tz":180,"elapsed":4355,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"357fa4f9-e4e6-4ffe-9f41-e42544a1ce4c"},"source":["# Load Data\n","\n","#### Data Path\n","PathDataSet = '../content/drive/MyDrive/Code/EXITS/Data/'\n","FileDataset = 'EXIST2021_translatedTraining'\n","#### Load tsv as a Data Frame\n","df_train = pd.read_csv(PathDataSet + FileDataset + '.csv', index_col=0)\n","\n","#### Create two new columns converting str labels to Num label\n","df_train['LabelTask1'] = df_train['task1'].apply(lambda x : 1 if x == 'sexist' else 0)\n","CategorisList = list(df_train.task2.unique())\n","CategorisList.remove('non-sexist')\n","CategorisList.insert(0,'non-sexist')\n","CategoriSexism = {CategorisList[index]: index for index in range(len(list(df_train.task2.unique())))}\n","df_train['LabelTask2'] = df_train['task2'].apply(lambda x : CategoriSexism[x])\n","\n","#### Get columns names\n","TestColumnNames = list(df_train.columns)\n","#### Vizualise Data\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>English</th>\n","      <th>Spanish</th>\n","      <th>LabelTask1</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021</td>\n","      <td>1</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>sexist</td>\n","      <td>ideological-inequality</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>Ella se llama \"anti-feminazi\", ¿cómo se acerca...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021</td>\n","      <td>2</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>Ahora, de vuelta a estas mujeres, la valiente ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021</td>\n","      <td>3</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>@Curvybandida @xalynne_b wow, tu falda es muy ...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021</td>\n","      <td>4</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>@Aurelieguiboud increíble!¡Hermoso! Pero me re...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EXIST2021</td>\n","      <td>5</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>i find it extremely hard to believe that kelly...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>i find it extremely hard to believe that kelly...</td>\n","      <td>Me parece extremadamente difícil creer que Kel...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_case  id  ... LabelTask1 LabelTask2\n","0  EXIST2021   1  ...          1          1\n","1  EXIST2021   2  ...          0          0\n","2  EXIST2021   3  ...          1          2\n","3  EXIST2021   4  ...          0          0\n","4  EXIST2021   5  ...          0          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Ot3u0gOYVND_","colab":{"base_uri":"https://localhost:8080/","height":572},"executionInfo":{"status":"ok","timestamp":1619288279816,"user_tz":180,"elapsed":531,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"348060f0-e11b-4034-92c7-d8e530a328a7"},"source":["######################################################\n","############## Moddify CODE ##########################\n","######################################################\n","\n","#### Change columns names for the train\n","LabelColumn = \"LabelTask1\"      ## \"LabelTask1\", \"LabelTask2\"\n","DataColumn = \"English\"          ## \"text\", \"English\" and \"Spanish\"\n","NewColumnsNames = {DataColumn:\"Data\",LabelColumn:\"Label\"}\n","df_train = df_train.rename(columns=NewColumnsNames)\n","# df_train = df_train.sample(frac=1).reset_index(drop=True)\n","\n","#### Vizualise Data\n","df_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","      <th>Label</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021</td>\n","      <td>1</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>sexist</td>\n","      <td>ideological-inequality</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>Ella se llama \"anti-feminazi\", ¿cómo se acerca...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021</td>\n","      <td>2</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>Ahora, de vuelta a estas mujeres, la valiente ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021</td>\n","      <td>3</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>@Curvybandida @xalynne_b wow, tu falda es muy ...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021</td>\n","      <td>4</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>@Aurelieguiboud increíble!¡Hermoso! Pero me re...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EXIST2021</td>\n","      <td>5</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>i find it extremely hard to believe that kelly...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>i find it extremely hard to believe that kelly...</td>\n","      <td>Me parece extremadamente difícil creer que Kel...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6972</th>\n","      <td>EXIST2021</td>\n","      <td>6973</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>Estamos igual sin pareja, pero puedes besar a ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>We are the same without a partner, but you can...</td>\n","      <td>Estamos igual sin pareja, pero puedes besar a ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6973</th>\n","      <td>EXIST2021</td>\n","      <td>6974</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>2020 hijo de re mil putas</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>2020 son of re thousand whores</td>\n","      <td>2020 hijo de re mil putas</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6974</th>\n","      <td>EXIST2021</td>\n","      <td>6975</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Surely this girl does not charge the money I w...</td>\n","      <td>SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6975</th>\n","      <td>EXIST2021</td>\n","      <td>6976</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>@safetyaitana mi madre dice q va fea y i agree</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","      <td>@safetyaitana my mother says that goes ugly an...</td>\n","      <td>@safetyaitana mi madre dice q va fea y i agree</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6976</th>\n","      <td>EXIST2021</td>\n","      <td>6977</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>¿En vuestras casas también tenéis esa tradició...</td>\n","      <td>sexist</td>\n","      <td>stereotyping-dominance</td>\n","      <td>In your houses you also have that tradition of...</td>\n","      <td>¿En vuestras casas también tenéis esa tradició...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6977 rows × 11 columns</p>\n","</div>"],"text/plain":["      test_case    id  ... Label LabelTask2\n","0     EXIST2021     1  ...     1          1\n","1     EXIST2021     2  ...     0          0\n","2     EXIST2021     3  ...     1          2\n","3     EXIST2021     4  ...     0          0\n","4     EXIST2021     5  ...     0          0\n","...         ...   ...  ...   ...        ...\n","6972  EXIST2021  6973  ...     0          0\n","6973  EXIST2021  6974  ...     0          0\n","6974  EXIST2021  6975  ...     0          0\n","6975  EXIST2021  6976  ...     1          2\n","6976  EXIST2021  6977  ...     1          4\n","\n","[6977 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"E4AXFmb4s0Yq"},"source":["######################################################\n","############## Moddify CODE ##########################\n","######################################################\n","\n","## Select Data for train\n","LanguageTrain = 'en'        ## 'Whole', 'en', 'es'\n","\n","df_train_es = df_train.loc[df_train.loc[df_train['language']== 'es' ].index[0]:df_train.loc[df_train['language']== 'es'].index[-1]]\n","df_train_en = df_train.loc[df_train.loc[df_train['language']== 'en' ].index[0]:df_train.loc[df_train['language']== 'en'].index[-1]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"NiXbq0xCtZuQ","executionInfo":{"status":"ok","timestamp":1619288285231,"user_tz":180,"elapsed":415,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"358a7422-f6d3-4fbb-b7d7-c4021e21da63"},"source":["## Get a Stratified sample of 20% of data/rows for Test (whole/es/en)\n","df_test_es = df_train_es.groupby(['Label']).apply(lambda x: x.sample(frac=0.2, random_state=48))\n","df_test_en = df_train_en.groupby(['Label']).apply(lambda x: x.sample(frac=0.2, random_state=48))\n","df_test_whole = pd.concat([df_test_es,df_test_en])\n","\n","#Selectin the data for the Standar Train and Test\n","if LanguageTrain == 'whole':\n","  df_test = df_test_whole\n","elif LanguageTrain == 'es':\n","  df_test = df_test_es\n","  df_train = df_train_es\n","elif LanguageTrain == 'en':\n","  df_test = df_test_en\n","  df_train = df_train_en\n","else:\n","  print('wrong data')\n","\n","df_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","      <th>Label</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","    <tr>\n","      <th>Label</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">0</th>\n","      <th>1540</th>\n","      <td>EXIST2021</td>\n","      <td>1541</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>Pero sí, Chuck yer libra y lata de frijoles y ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>EXIST2021</td>\n","      <td>176</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>@ IDEW2 @MSButterflyyy en un tweet sobre el ra...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1081</th>\n","      <td>EXIST2021</td>\n","      <td>1082</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>@Crryptiic @nagitoosimp no es solo acoso sexua...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>EXIST2021</td>\n","      <td>451</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>@realdonaldtrump Estos son los temas anteriore...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2953</th>\n","      <td>EXIST2021</td>\n","      <td>2954</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>Como realmente no me importa y no sea realment...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            test_case    id  ... Label LabelTask2\n","Label                        ...                 \n","0     1540  EXIST2021  1541  ...     0          0\n","      175   EXIST2021   176  ...     0          0\n","      1081  EXIST2021  1082  ...     0          0\n","      450   EXIST2021   451  ...     0          0\n","      2953  EXIST2021  2954  ...     0          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"QOz07KEfv1Ex","executionInfo":{"status":"ok","timestamp":1619288287803,"user_tz":180,"elapsed":502,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"b971fad0-469c-41b2-98e3-3f29ac7025bd"},"source":["# Removing Extra Index levels\n","df_test_es = df_test_es.reset_index(level=0, drop=True)\n","df_test_en = df_test_en.reset_index(level=0, drop=True)\n","df_test_whole = df_test_whole.reset_index(level=0, drop=True)\n","\n","# Importantt for remove index in the next cell\n","df_test = df_test.reset_index(level=0, drop=True)\n","\n","# Checking the Data\n","df_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","      <th>Label</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1540</th>\n","      <td>EXIST2021</td>\n","      <td>1541</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>Pero sí, Chuck yer libra y lata de frijoles y ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>EXIST2021</td>\n","      <td>176</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>@ IDEW2 @MSButterflyyy en un tweet sobre el ra...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1081</th>\n","      <td>EXIST2021</td>\n","      <td>1082</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>@Crryptiic @nagitoosimp no es solo acoso sexua...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>450</th>\n","      <td>EXIST2021</td>\n","      <td>451</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>@realdonaldtrump Estos son los temas anteriore...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2953</th>\n","      <td>EXIST2021</td>\n","      <td>2954</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>Como realmente no me importa y no sea realment...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      test_case    id  ... Label LabelTask2\n","1540  EXIST2021  1541  ...     0          0\n","175   EXIST2021   176  ...     0          0\n","1081  EXIST2021  1082  ...     0          0\n","450   EXIST2021   451  ...     0          0\n","2953  EXIST2021  2954  ...     0          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"UKKctDQhJwVG","executionInfo":{"status":"ok","timestamp":1619288290072,"user_tz":180,"elapsed":542,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"9b87fde5-2c17-4895-849b-19d76e9f81c2"},"source":["# Remove the data/rows used for test set from the train set\n","df_train = df_train.drop(df_test.index)\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","      <th>Label</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021</td>\n","      <td>1</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>sexist</td>\n","      <td>ideological-inequality</td>\n","      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n","      <td>Ella se llama \"anti-feminazi\", ¿cómo se acerca...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021</td>\n","      <td>2</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Now, back to these women, the brave and the be...</td>\n","      <td>Ahora, de vuelta a estas mujeres, la valiente ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021</td>\n","      <td>3</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n","      <td>@Curvybandida @xalynne_b wow, tu falda es muy ...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021</td>\n","      <td>4</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n","      <td>@Aurelieguiboud increíble!¡Hermoso! Pero me re...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>EXIST2021</td>\n","      <td>7</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@Texas17761 @MomsDemand True story: Me to 18 y...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@Texas17761 @MomsDemand True story: Me to 18 y...</td>\n","      <td>@ Texas17761 @momsdemand True Story: Me a 18 y...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_case  id  ... Label LabelTask2\n","0  EXIST2021   1  ...     1          1\n","1  EXIST2021   2  ...     0          0\n","2  EXIST2021   3  ...     1          2\n","3  EXIST2021   4  ...     0          0\n","6  EXIST2021   7  ...     0          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"jun8Iq8Eyinz","executionInfo":{"status":"ok","timestamp":1619288292156,"user_tz":180,"elapsed":697,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"d61f55b4-40ef-443a-e5ce-d8098de0b013"},"source":["# Reset index datframes and and Remove non-sexist rows if task 2 \n","#### Remove non-sexist rows if task 2 \n","if df_train['Label'].nunique() > 2:\n","\n","  df_train = df_train[df_train['Label'] != 0]\n","  df_train_es = df_train_es[df_train_es['Label'] != 0]\n","  df_train_en = df_train_en[df_train_en['Label'] != 0]\n","\n","  df_test = df_test[df_test['Label'] != 0]\n","  df_test_whole = df_test_whole[df_test_whole['Label'] != 0]\n","  df_test_en = df_test_en[df_test_en['Label'] != 0]\n","  df_test_es = df_test_es[df_test_es['Label'] != 0]\n","\n","#### Reset index\n","df_train = df_train.reset_index(drop=True)\n","df_train_es = df_train_es.reset_index(drop=True)\n","df_train_en = df_train_en.reset_index(drop=True)\n","\n","df_test = df_test.reset_index(drop=True)\n","df_test_whole = df_test_whole.reset_index(drop=True)\n","df_test_en = df_test_en.reset_index(drop=True)\n","df_test_es = df_test_es.reset_index(drop=True)\n"," \n","df_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","      <th>Label</th>\n","      <th>LabelTask2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021</td>\n","      <td>1541</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>But yeah, Chuck yer pound and tin of beans in ...</td>\n","      <td>Pero sí, Chuck yer libra y lata de frijoles y ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021</td>\n","      <td>176</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@idew2 @MsButterflyyy In a tweet about systemi...</td>\n","      <td>@ IDEW2 @MSButterflyyy en un tweet sobre el ra...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021</td>\n","      <td>1082</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@Crryptiic @nagitoosimp Isn’t it just sexual h...</td>\n","      <td>@Crryptiic @nagitoosimp no es solo acoso sexua...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021</td>\n","      <td>451</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>@realDonaldTrump these are past Speech Topics ...</td>\n","      <td>@realdonaldtrump Estos son los temas anteriore...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EXIST2021</td>\n","      <td>2954</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","      <td>Like I don't really care and misandry ain't re...</td>\n","      <td>Como realmente no me importa y no sea realment...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_case    id  ... Label LabelTask2\n","0  EXIST2021  1541  ...     0          0\n","1  EXIST2021   176  ...     0          0\n","2  EXIST2021  1082  ...     0          0\n","3  EXIST2021   451  ...     0          0\n","4  EXIST2021  2954  ...     0          0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"3I3eUmvE3zPa"},"source":["#Load Weights"]},{"cell_type":"code","metadata":{"id":"OtRdnS-Rz3m0"},"source":["def CriateFileName(BertVersionDict, NumberOfClasses):\n","  \n","  NameFile = str()\n","  for BertModel in BertVersionDict.keys():\n","    NameFile += BertModel\n","\n","  if NumberOfClasses > 2:\n","    NameFile += 'Task2'\n","  else:\n","    NameFile += 'Task1'\n","\n","  return NameFile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miaaavjhYUp-"},"source":["# BertVersion = {'EnglishBert':'../content/bert-base-uncased/', 'SpanishBert':'../content/bert-base-spanish-wwm-uncased/', 'MultilingualBert':'../content/bert-base-multilingual-uncased/'}\n","# OutputBert = ['hidden', 'pooler']\n","# LearningRate = [2e-5, 3e-5, 5e-5]\n","# BatchSize = [32, 64]\n","# Epochs = 8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIB8biWBisK-"},"source":["######################################################\n","############## Moddify CODE - BERT model #############\n","######################################################\n","\n","## Train Parameters\n","BertVersion = {'EnglishBert':'../content/bert-base-uncased/'}\n","OutputBert = ['hidden', 'pooler']\n","LearningRate = [2e-5, 3e-5, 5e-5]\n","BatchSize = [32, 64]\n","Epochs = 8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exc5VakSaf7N"},"source":["## Evalute matrics\n","###### Task 1\n","MetricsTask1 = ['accuracy', 'f1', 'recall', 'precision']\n","###### Task 2\n","MetricsTask2 = ['accuracy', 'f1_macro', 'f1_weighted', 'recall', 'precision']\n","\n","## Get for 'Binary' classification' task1 or 'Multilabel classifcation' task2\n","Metrics = MetricsTask2 if df_train['Label'].nunique() > 2 else MetricsTask1\n","\n","## Criate dictinaril results\n","ResultsTask = { bert:{ output:{ lr:{ bat:{ epoc:{ metric:[] for metric in Metrics + ['loss']} for epoc in range(1, Epochs+1) } for bat in BatchSize} for lr in LearningRate} for output in OutputBert } for bert in BertVersion.keys() }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjxtRdNL2Kus","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619288318514,"user_tz":180,"elapsed":1358,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"b236dc9b-1ba9-46eb-abae-5935774d49cb"},"source":["## Where to Save Files\n","Path = 'drive/MyDrive/Code/EXITS/Machine-Learning-Tweets-Classification/Bert/Results/' \n","BertModels = ''\n","for b in list(BertVersion.keys()):\n","  BertModels =  BertModels  + b + '_'\n","Folder = BertModels + LanguageTrain\n","Path = Path + Folder + 'DataTrain' + '/'\n","\n","## Criate file to save results if it does not exist \n","if not os.path.exists(Path):\n","  print(f'Criate folder : {Folder}' )\n","  print(f'Path : {Path}')\n","  os.makedirs(Path)\n","\n","## Creating Main Parte Bert File Name\n","MainParteBertFileName = CriateFileName(BertVersion, NumberOfClasses=df_train['Label'].nunique()) + LanguageTrain\n","\n","## Create file to save results if it does not existe\n","FileResults = MainParteBertFileName + 'DataTrain' + '_Results'\n","if not os.path.exists(Path + FileResults + '.pkl'):\n","  print(f'Creating File for results : {FileResults}.pkl')\n","  print(f'File Path : {Path}')\n","  with open(Path + FileResults + \".pkl\",'wb') as f:\n","    pickle.dump(ResultsTask, f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating File for results : EnglishBertTask1enDataTrain_Results.pkl\n","File Path : drive/MyDrive/Code/EXITS/Machine-Learning-Tweets-Classification/Bert/Results/EnglishBert_enDataTrain/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RefkYdGrcgmy"},"source":["#Train"]},{"cell_type":"code","metadata":{"id":"Lb1R26k9lFXG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619268306509,"user_tz":180,"elapsed":8833200,"user":{"displayName":"Marieli Lauxen","photoUrl":"","userId":"02046508060582016885"}},"outputId":"55c6b194-617a-49ef-c086-90c11b9b400e"},"source":["### Cross Validation\n","for BertV, BertPath in BertVersion.items():\n","  for OutputB in OutputBert:\n","\n","    ### Loading Bert trained weights\n","    mx = BERTBaseUncased(bert_path=BertPath, output_bert=OutputB, NumberOfClasses=df_train['Label'].nunique())\n","\n","    for lr in LearningRate:\n","      for Batch in BatchSize:\n","\n","        ## StratifiedKFold\n","        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=48)\n","        fold = 1\n","        for train_index, valid_index in skf.split(df_train['Data'], df_train['Label']):\n","          X_train, X_valid = df_train.loc[train_index, 'Data'], df_train.loc[valid_index, 'Data']\n","          y_train, y_valid = df_train.loc[train_index, 'Label'], df_train.loc[valid_index, 'Label']\n","\n","          print(f'parameters: Bertmodel: {BertV}, Output: {OutputB}, lr: {lr}, Batch: {Batch}, Totsl Num. Epochs: {Epochs}, Fold: {fold}')\n","          fold += 1\n","          MoDeL = TrainModel(PathSaveFiles = Path,\n","                            BertVersion=BertV,\n","                            BertPath=BertPath,\n","                            OutputBert=OutputB,\n","                            LearningRate=lr,\n","                            BatchSize=Batch,\n","                            Epochs=Epochs,\n","                            FileName= FileResults,\n","                            X_train=X_train, \n","                            X_valid=X_valid,\n","                            y_train=y_train,\n","                            y_valid=y_valid)\n","        \n","\n","          def _mp_fn(rank, flags):\n","            torch.set_default_tensor_type('torch.FloatTensor')\n","            a = MoDeL._run()\n","\n","          FLAGS={}\n","          xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.651019275188446\n","Accuracy = 0.6285714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.612134575843811\n","Accuracy = 0.7428571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.4129303991794586\n","Accuracy = 0.7392857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.43036898970603943\n","Accuracy = 0.775\n","Epoch: 5 of 8\n","bi=0, loss=0.18055954575538635\n","Accuracy = 0.7785714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.1291235238313675\n","Accuracy = 0.7857142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.08474749326705933\n","Accuracy = 0.7857142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.04319370910525322\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7625068426132202\n","Accuracy = 0.6821428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.6414949893951416\n","Accuracy = 0.7357142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.3599924147129059\n","Accuracy = 0.8\n","Epoch: 4 of 8\n","bi=0, loss=0.23749443888664246\n","Accuracy = 0.8035714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.13344475626945496\n","Accuracy = 0.8178571428571428\n","Epoch: 6 of 8\n","bi=0, loss=0.099908746778965\n","Accuracy = 0.8071428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.11943835020065308\n","Accuracy = 0.8\n","Epoch: 8 of 8\n","bi=0, loss=0.07654471695423126\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6706521511077881\n","Accuracy = 0.6142857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.5601134896278381\n","Accuracy = 0.6964285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.3744131028652191\n","Accuracy = 0.7857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.27387234568595886\n","Accuracy = 0.7892857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.12756559252738953\n","Accuracy = 0.8\n","Epoch: 6 of 8\n","bi=0, loss=0.07988078892230988\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.048571087419986725\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.1259680688381195\n","Accuracy = 0.7892857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6985777020454407\n","Accuracy = 0.6428571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.5631347894668579\n","Accuracy = 0.7285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.31898292899131775\n","Accuracy = 0.7678571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.27695369720458984\n","Accuracy = 0.7642857142857142\n","Epoch: 5 of 8\n","bi=0, loss=0.20558911561965942\n","Accuracy = 0.7642857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.0783233717083931\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.07580681145191193\n","Accuracy = 0.7714285714285715\n","Epoch: 8 of 8\n","bi=0, loss=0.04750023037195206\n","Accuracy = 0.7892857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6604090929031372\n","Accuracy = 0.6607142857142857\n","Epoch: 2 of 8\n","bi=0, loss=0.6528844833374023\n","Accuracy = 0.7607142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.5121485590934753\n","Accuracy = 0.775\n","Epoch: 4 of 8\n","bi=0, loss=0.4408594071865082\n","Accuracy = 0.7785714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.24159500002861023\n","Accuracy = 0.7714285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.08428995311260223\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.1553107500076294\n","Accuracy = 0.7821428571428573\n","Epoch: 8 of 8\n","bi=0, loss=0.05531061068177223\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.737657368183136\n","Accuracy = 0.5964285714285713\n","Epoch: 2 of 8\n","bi=0, loss=0.6634566187858582\n","Accuracy = 0.675\n","Epoch: 3 of 8\n","bi=0, loss=0.5428172945976257\n","Accuracy = 0.7035714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.5386406183242798\n","Accuracy = 0.75\n","Epoch: 5 of 8\n","bi=0, loss=0.32671791315078735\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.2898148000240326\n","Accuracy = 0.7392857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.2082565873861313\n","Accuracy = 0.7392857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.096192866563797\n","Accuracy = 0.7214285714285714\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8004893660545349\n","Accuracy = 0.6178571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.6228199601173401\n","Accuracy = 0.7392857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.5175805687904358\n","Accuracy = 0.775\n","Epoch: 4 of 8\n","bi=0, loss=0.40553873777389526\n","Accuracy = 0.7821428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.32460373640060425\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.253061443567276\n","Accuracy = 0.8\n","Epoch: 7 of 8\n","bi=0, loss=0.20255866646766663\n","Accuracy = 0.775\n","Epoch: 8 of 8\n","bi=0, loss=0.13131612539291382\n","Accuracy = 0.7857142857142857\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7115177512168884\n","Accuracy = 0.6142857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.6375017166137695\n","Accuracy = 0.7535714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.5726020932197571\n","Accuracy = 0.7321428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.4704454243183136\n","Accuracy = 0.8071428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.321845144033432\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.2523704469203949\n","Accuracy = 0.7821428571428573\n","Epoch: 7 of 8\n","bi=0, loss=0.20589976012706757\n","Accuracy = 0.75\n","Epoch: 8 of 8\n","bi=0, loss=0.18951234221458435\n","Accuracy = 0.7821428571428571\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7584229111671448\n","Accuracy = 0.5964285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6051979064941406\n","Accuracy = 0.675\n","Epoch: 3 of 8\n","bi=0, loss=0.5508295297622681\n","Accuracy = 0.7214285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.36882591247558594\n","Accuracy = 0.7428571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.27932313084602356\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.1772986799478531\n","Accuracy = 0.75\n","Epoch: 7 of 8\n","bi=0, loss=0.09696543216705322\n","Accuracy = 0.7321428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.10136781632900238\n","Accuracy = 0.7214285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.73188716173172\n","Accuracy = 0.6714285714285715\n","Epoch: 2 of 8\n","bi=0, loss=0.5842101573944092\n","Accuracy = 0.7678571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.541163444519043\n","Accuracy = 0.8035714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.38291865587234497\n","Accuracy = 0.7821428571428573\n","Epoch: 5 of 8\n","bi=0, loss=0.23013503849506378\n","Accuracy = 0.8035714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.1410420536994934\n","Accuracy = 0.8071428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.058755673468112946\n","Accuracy = 0.8035714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.03475029766559601\n","Accuracy = 0.8035714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7107480764389038\n","Accuracy = 0.525\n","Epoch: 2 of 8\n","bi=0, loss=0.6829816102981567\n","Accuracy = 0.6428571428571428\n","Epoch: 3 of 8\n","bi=0, loss=0.6386740803718567\n","Accuracy = 0.6714285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.5410653948783875\n","Accuracy = 0.7392857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.500756561756134\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.46653613448143005\n","Accuracy = 0.7428571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.4091283082962036\n","Accuracy = 0.7392857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.38980695605278015\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.734194278717041\n","Accuracy = 0.5392857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.7628026008605957\n","Accuracy = 0.6928571428571428\n","Epoch: 3 of 8\n","bi=0, loss=0.6422199010848999\n","Accuracy = 0.717857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.6104010343551636\n","Accuracy = 0.7642857142857142\n","Epoch: 5 of 8\n","bi=0, loss=0.5586456060409546\n","Accuracy = 0.775\n","Epoch: 6 of 8\n","bi=0, loss=0.4300483763217926\n","Accuracy = 0.7821428571428573\n","Epoch: 7 of 8\n","bi=0, loss=0.37558746337890625\n","Accuracy = 0.7928571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.3684440553188324\n","Accuracy = 0.7857142857142858\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6696865558624268\n","Accuracy = 0.5285714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.664064884185791\n","Accuracy = 0.5928571428571427\n","Epoch: 3 of 8\n","bi=0, loss=0.577520489692688\n","Accuracy = 0.6464285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.5521419048309326\n","Accuracy = 0.6642857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.4571691155433655\n","Accuracy = 0.7071428571428571\n","Epoch: 6 of 8\n","bi=0, loss=0.39720654487609863\n","Accuracy = 0.7428571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.32601988315582275\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.26669180393218994\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6783586740493774\n","Accuracy = 0.5071428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6177822947502136\n","Accuracy = 0.6571428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.5999459028244019\n","Accuracy = 0.6821428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.5260679125785828\n","Accuracy = 0.7142857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.4856283664703369\n","Accuracy = 0.7357142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.4322824478149414\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.38194283843040466\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.3418772518634796\n","Accuracy = 0.7678571428571428\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7039778828620911\n","Accuracy = 0.65\n","Epoch: 2 of 8\n","bi=0, loss=0.6689925789833069\n","Accuracy = 0.6892857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.5963611602783203\n","Accuracy = 0.725\n","Epoch: 4 of 8\n","bi=0, loss=0.5813940167427063\n","Accuracy = 0.7321428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.5276439189910889\n","Accuracy = 0.7607142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.423005610704422\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.4017377197742462\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.33517464995384216\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7516173720359802\n","Accuracy = 0.5357142857142857\n","Epoch: 2 of 8\n","bi=0, loss=0.7142651677131653\n","Accuracy = 0.6035714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.6737827062606812\n","Accuracy = 0.6392857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.5516368746757507\n","Accuracy = 0.675\n","Epoch: 5 of 8\n","bi=0, loss=0.5048506855964661\n","Accuracy = 0.7107142857142856\n","Epoch: 6 of 8\n","bi=0, loss=0.43499958515167236\n","Accuracy = 0.7214285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.4687848687171936\n","Accuracy = 0.725\n","Epoch: 8 of 8\n","bi=0, loss=0.3579975366592407\n","Accuracy = 0.7321428571428571\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7508322596549988\n","Accuracy = 0.5\n","Epoch: 2 of 8\n","bi=0, loss=0.6665776371955872\n","Accuracy = 0.5964285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.6222347617149353\n","Accuracy = 0.6678571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.5843674540519714\n","Accuracy = 0.7464285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.5596228837966919\n","Accuracy = 0.75\n","Epoch: 6 of 8\n","bi=0, loss=0.5262839198112488\n","Accuracy = 0.75\n","Epoch: 7 of 8\n","bi=0, loss=0.48850420117378235\n","Accuracy = 0.7642857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.5130004286766052\n","Accuracy = 0.7821428571428571\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7093284130096436\n","Accuracy = 0.5821428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6658708453178406\n","Accuracy = 0.6714285714285715\n","Epoch: 3 of 8\n","bi=0, loss=0.6378310918807983\n","Accuracy = 0.6892857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.589917778968811\n","Accuracy = 0.7357142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.5687173008918762\n","Accuracy = 0.7464285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.4830085039138794\n","Accuracy = 0.7785714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.4015296697616577\n","Accuracy = 0.7892857142857144\n","Epoch: 8 of 8\n","bi=0, loss=0.37904345989227295\n","Accuracy = 0.7999999999999999\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.756084144115448\n","Accuracy = 0.5035714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.7060264348983765\n","Accuracy = 0.5714285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.6602268218994141\n","Accuracy = 0.6357142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.583896815776825\n","Accuracy = 0.6928571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.5784717798233032\n","Accuracy = 0.7035714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.49523866176605225\n","Accuracy = 0.7071428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.4387458860874176\n","Accuracy = 0.7178571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.357636421918869\n","Accuracy = 0.7321428571428572\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7264255285263062\n","Accuracy = 0.5678571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7118094563484192\n","Accuracy = 0.6535714285714287\n","Epoch: 3 of 8\n","bi=0, loss=0.6243170499801636\n","Accuracy = 0.7357142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.5707645416259766\n","Accuracy = 0.7428571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.5436620712280273\n","Accuracy = 0.7714285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.46608051657676697\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.409332811832428\n","Accuracy = 0.7642857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.35941407084465027\n","Accuracy = 0.7857142857142858\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.651019275188446\n","Accuracy = 0.6714285714285715\n","Epoch: 2 of 8\n","bi=0, loss=0.556852400302887\n","Accuracy = 0.725\n","Epoch: 3 of 8\n","bi=0, loss=0.3920629918575287\n","Accuracy = 0.7321428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.41447457671165466\n","Accuracy = 0.7928571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.14752495288848877\n","Accuracy = 0.7892857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.055095404386520386\n","Accuracy = 0.7821428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.04923471435904503\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.03619299456477165\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7625068426132202\n","Accuracy = 0.6642857142857144\n","Epoch: 2 of 8\n","bi=0, loss=0.6234784722328186\n","Accuracy = 0.7428571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.3012084364891052\n","Accuracy = 0.8\n","Epoch: 4 of 8\n","bi=0, loss=0.14314493536949158\n","Accuracy = 0.8071428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.12259895354509354\n","Accuracy = 0.8071428571428572\n","Epoch: 6 of 8\n","bi=0, loss=0.046330250799655914\n","Accuracy = 0.7964285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.04538901895284653\n","Accuracy = 0.7821428571428573\n","Epoch: 8 of 8\n","bi=0, loss=0.04464728385210037\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6706521511077881\n","Accuracy = 0.65\n","Epoch: 2 of 8\n","bi=0, loss=0.5230985879898071\n","Accuracy = 0.7535714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.2895139157772064\n","Accuracy = 0.7857142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.09900452196598053\n","Accuracy = 0.7857142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.04532833769917488\n","Accuracy = 0.7821428571428571\n","Epoch: 6 of 8\n","bi=0, loss=0.052234992384910583\n","Accuracy = 0.7928571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.0064304242841899395\n","Accuracy = 0.7857142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.1648237556219101\n","Accuracy = 0.7392857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6985777020454407\n","Accuracy = 0.6607142857142857\n","Epoch: 2 of 8\n","bi=0, loss=0.5419228672981262\n","Accuracy = 0.7571428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.2784973382949829\n","Accuracy = 0.7964285714285715\n","Epoch: 4 of 8\n","bi=0, loss=0.2033866047859192\n","Accuracy = 0.7607142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.14151683449745178\n","Accuracy = 0.775\n","Epoch: 6 of 8\n","bi=0, loss=0.04819946736097336\n","Accuracy = 0.7678571428571428\n","Epoch: 7 of 8\n","bi=0, loss=0.036560069769620895\n","Accuracy = 0.7857142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.021145323291420937\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6604090929031372\n","Accuracy = 0.6499999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.6435772180557251\n","Accuracy = 0.75\n","Epoch: 3 of 8\n","bi=0, loss=0.4768933057785034\n","Accuracy = 0.7857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.3429626524448395\n","Accuracy = 0.7821428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.1763874590396881\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.05431854724884033\n","Accuracy = 0.7714285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.03482405096292496\n","Accuracy = 0.7678571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.010199146345257759\n","Accuracy = 0.7857142857142858\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.737657368183136\n","Accuracy = 0.6392857142857142\n","Epoch: 2 of 8\n","bi=0, loss=0.5869821906089783\n","Accuracy = 0.7178571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.5283142924308777\n","Accuracy = 0.7250000000000001\n","Epoch: 4 of 8\n","bi=0, loss=0.3113653063774109\n","Accuracy = 0.75\n","Epoch: 5 of 8\n","bi=0, loss=0.28199177980422974\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.13890768587589264\n","Accuracy = 0.7357142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.03765032812952995\n","Accuracy = 0.7464285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.015640856698155403\n","Accuracy = 0.7392857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8004893660545349\n","Accuracy = 0.6464285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6178365349769592\n","Accuracy = 0.7535714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.5045986175537109\n","Accuracy = 0.775\n","Epoch: 4 of 8\n","bi=0, loss=0.3355061113834381\n","Accuracy = 0.7928571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.16843357682228088\n","Accuracy = 0.8\n","Epoch: 6 of 8\n","bi=0, loss=0.14939984679222107\n","Accuracy = 0.7607142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.039925914257764816\n","Accuracy = 0.7750000000000001\n","Epoch: 8 of 8\n","bi=0, loss=0.007095240522176027\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7115177512168884\n","Accuracy = 0.6892857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.5768481492996216\n","Accuracy = 0.775\n","Epoch: 3 of 8\n","bi=0, loss=0.5137435793876648\n","Accuracy = 0.8071428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.31322112679481506\n","Accuracy = 0.7785714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.2810954451560974\n","Accuracy = 0.7892857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.1298447996377945\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.1132870614528656\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.028593743219971657\n","Accuracy = 0.7964285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7584229111671448\n","Accuracy = 0.5714285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.5992672443389893\n","Accuracy = 0.6821428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.5202431678771973\n","Accuracy = 0.7321428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.3693934381008148\n","Accuracy = 0.7535714285714287\n","Epoch: 5 of 8\n","bi=0, loss=0.24168668687343597\n","Accuracy = 0.7642857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.1446232795715332\n","Accuracy = 0.7464285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.03454066440463066\n","Accuracy = 0.7285714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.02832299843430519\n","Accuracy = 0.7214285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.73188716173172\n","Accuracy = 0.6821428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.5999706387519836\n","Accuracy = 0.7642857142857142\n","Epoch: 3 of 8\n","bi=0, loss=0.5121397972106934\n","Accuracy = 0.7928571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.24138294160366058\n","Accuracy = 0.8\n","Epoch: 5 of 8\n","bi=0, loss=0.15655313432216644\n","Accuracy = 0.7964285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.07451280951499939\n","Accuracy = 0.7964285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.03232172876596451\n","Accuracy = 0.8\n","Epoch: 8 of 8\n","bi=0, loss=0.015026004053652287\n","Accuracy = 0.7821428571428573\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7107480764389038\n","Accuracy = 0.5571428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.6685883402824402\n","Accuracy = 0.6464285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.6174232363700867\n","Accuracy = 0.6964285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.5239439606666565\n","Accuracy = 0.7392857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.452767014503479\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.4478495419025421\n","Accuracy = 0.7571428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.3508926033973694\n","Accuracy = 0.7678571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.2477315068244934\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.734194278717041\n","Accuracy = 0.5785714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.726976752281189\n","Accuracy = 0.7071428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.635269284248352\n","Accuracy = 0.7535714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.5293536186218262\n","Accuracy = 0.7607142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.5344617962837219\n","Accuracy = 0.7642857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.4113437831401825\n","Accuracy = 0.7857142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.29061630368232727\n","Accuracy = 0.7892857142857144\n","Epoch: 8 of 8\n","bi=0, loss=0.3041808307170868\n","Accuracy = 0.7892857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6696865558624268\n","Accuracy = 0.5535714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6315107345581055\n","Accuracy = 0.6\n","Epoch: 3 of 8\n","bi=0, loss=0.5776119232177734\n","Accuracy = 0.6821428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.49057337641716003\n","Accuracy = 0.6964285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.3628929853439331\n","Accuracy = 0.7285714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.33011889457702637\n","Accuracy = 0.7785714285714287\n","Epoch: 7 of 8\n","bi=0, loss=0.23948262631893158\n","Accuracy = 0.7785714285714287\n","Epoch: 8 of 8\n","bi=0, loss=0.18163709342479706\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6783586740493774\n","Accuracy = 0.532142857142857\n","Epoch: 2 of 8\n","bi=0, loss=0.6083690524101257\n","Accuracy = 0.6714285714285715\n","Epoch: 3 of 8\n","bi=0, loss=0.599022626876831\n","Accuracy = 0.7035714285714285\n","Epoch: 4 of 8\n","bi=0, loss=0.4942019283771515\n","Accuracy = 0.7178571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.49322056770324707\n","Accuracy = 0.7321428571428572\n","Epoch: 6 of 8\n","bi=0, loss=0.4081064462661743\n","Accuracy = 0.7571428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.35666701197624207\n","Accuracy = 0.7642857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.29812508821487427\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7039778828620911\n","Accuracy = 0.6107142857142858\n","Epoch: 2 of 8\n","bi=0, loss=0.6518941521644592\n","Accuracy = 0.6178571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.5688870549201965\n","Accuracy = 0.7642857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.49864843487739563\n","Accuracy = 0.7607142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.4659667909145355\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.39022889733314514\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.2968062460422516\n","Accuracy = 0.7714285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.23269303143024445\n","Accuracy = 0.7714285714285714\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7516173720359802\n","Accuracy = 0.5178571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7063818573951721\n","Accuracy = 0.625\n","Epoch: 3 of 8\n","bi=0, loss=0.6698010563850403\n","Accuracy = 0.6285714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.5513079166412354\n","Accuracy = 0.7035714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.5058879852294922\n","Accuracy = 0.7178571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.41164809465408325\n","Accuracy = 0.7250000000000001\n","Epoch: 7 of 8\n","bi=0, loss=0.42166751623153687\n","Accuracy = 0.7214285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.29144832491874695\n","Accuracy = 0.7178571428571427\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7508322596549988\n","Accuracy = 0.4964285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6571051478385925\n","Accuracy = 0.5857142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6171098947525024\n","Accuracy = 0.6428571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.5912035703659058\n","Accuracy = 0.7464285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.54999840259552\n","Accuracy = 0.7464285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.5092810392379761\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.4666968286037445\n","Accuracy = 0.7857142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.4592370390892029\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7093284130096436\n","Accuracy = 0.5785714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.6518282294273376\n","Accuracy = 0.6642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.613358199596405\n","Accuracy = 0.7\n","Epoch: 4 of 8\n","bi=0, loss=0.5743809938430786\n","Accuracy = 0.7642857142857142\n","Epoch: 5 of 8\n","bi=0, loss=0.4999167323112488\n","Accuracy = 0.775\n","Epoch: 6 of 8\n","bi=0, loss=0.3738558292388916\n","Accuracy = 0.7821428571428573\n","Epoch: 7 of 8\n","bi=0, loss=0.32394781708717346\n","Accuracy = 0.8\n","Epoch: 8 of 8\n","bi=0, loss=0.2575574517250061\n","Accuracy = 0.7892857142857144\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.756084144115448\n","Accuracy = 0.49285714285714277\n","Epoch: 2 of 8\n","bi=0, loss=0.7206991910934448\n","Accuracy = 0.5464285714285715\n","Epoch: 3 of 8\n","bi=0, loss=0.6561562418937683\n","Accuracy = 0.6035714285714285\n","Epoch: 4 of 8\n","bi=0, loss=0.590038001537323\n","Accuracy = 0.6928571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.5594446659088135\n","Accuracy = 0.7035714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.49667248129844666\n","Accuracy = 0.7214285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.4028150141239166\n","Accuracy = 0.7214285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.3471227288246155\n","Accuracy = 0.7357142857142858\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7264255285263062\n","Accuracy = 0.6535714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.6712578535079956\n","Accuracy = 0.7107142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6193782687187195\n","Accuracy = 0.7142857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.5244412422180176\n","Accuracy = 0.7571428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.48267579078674316\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.3864065110683441\n","Accuracy = 0.7857142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.3201757073402405\n","Accuracy = 0.7857142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.25190111994743347\n","Accuracy = 0.7857142857142857\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.651019275188446\n","Accuracy = 0.7\n","Epoch: 2 of 8\n","bi=0, loss=0.5442588925361633\n","Accuracy = 0.7642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.4066910743713379\n","Accuracy = 0.7678571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.3185339868068695\n","Accuracy = 0.7392857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.05766349285840988\n","Accuracy = 0.7857142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.1140524223446846\n","Accuracy = 0.7285714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.020007899031043053\n","Accuracy = 0.7535714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.005346204154193401\n","Accuracy = 0.7392857142857143\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7625068426132202\n","Accuracy = 0.6321428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6483891606330872\n","Accuracy = 0.7357142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.3255713880062103\n","Accuracy = 0.7857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.138192817568779\n","Accuracy = 0.7964285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.1243671402335167\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.06708821654319763\n","Accuracy = 0.8\n","Epoch: 7 of 8\n","bi=0, loss=0.03458848595619202\n","Accuracy = 0.7714285714285715\n","Epoch: 8 of 8\n","bi=0, loss=0.0242509413510561\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6706521511077881\n","Accuracy = 0.6642857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.5599541664123535\n","Accuracy = 0.7857142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.23648327589035034\n","Accuracy = 0.7678571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.07651032507419586\n","Accuracy = 0.7464285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.017788955941796303\n","Accuracy = 0.7928571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.03187313303351402\n","Accuracy = 0.7464285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.10387983173131943\n","Accuracy = 0.7857142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.0075025358237326145\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6985777020454407\n","Accuracy = 0.65\n","Epoch: 2 of 8\n","bi=0, loss=0.5869066119194031\n","Accuracy = 0.7392857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.36217576265335083\n","Accuracy = 0.7714285714285715\n","Epoch: 4 of 8\n","bi=0, loss=0.13723988831043243\n","Accuracy = 0.7357142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.20619463920593262\n","Accuracy = 0.7678571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.05928685516119003\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.17760786414146423\n","Accuracy = 0.7428571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.019898585975170135\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6604090929031372\n","Accuracy = 0.6285714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6923062801361084\n","Accuracy = 0.7678571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.5808886885643005\n","Accuracy = 0.7607142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.3455522656440735\n","Accuracy = 0.7678571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.17655593156814575\n","Accuracy = 0.7892857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.03756549954414368\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.06211375445127487\n","Accuracy = 0.7749999999999999\n","Epoch: 8 of 8\n","bi=0, loss=0.0067661600187420845\n","Accuracy = 0.7607142857142857\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.737657368183136\n","Accuracy = 0.6142857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.5723439455032349\n","Accuracy = 0.7\n","Epoch: 3 of 8\n","bi=0, loss=0.4757313132286072\n","Accuracy = 0.7535714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.4163989722728729\n","Accuracy = 0.7714285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.22497449815273285\n","Accuracy = 0.7285714285714285\n","Epoch: 6 of 8\n","bi=0, loss=0.10000841319561005\n","Accuracy = 0.7321428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.024706896394491196\n","Accuracy = 0.7464285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.011258173733949661\n","Accuracy = 0.7464285714285714\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8004893660545349\n","Accuracy = 0.6321428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6396058201789856\n","Accuracy = 0.75\n","Epoch: 3 of 8\n","bi=0, loss=0.41909390687942505\n","Accuracy = 0.7821428571428573\n","Epoch: 4 of 8\n","bi=0, loss=0.2577679753303528\n","Accuracy = 0.7928571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.14246155321598053\n","Accuracy = 0.7714285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.06071754917502403\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.02889363467693329\n","Accuracy = 0.775\n","Epoch: 8 of 8\n","bi=0, loss=0.050104204565286636\n","Accuracy = 0.7750000000000001\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7115177512168884\n","Accuracy = 0.6964285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6076162457466125\n","Accuracy = 0.7464285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.5101327896118164\n","Accuracy = 0.7821428571428573\n","Epoch: 4 of 8\n","bi=0, loss=0.2920820713043213\n","Accuracy = 0.7571428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.2597607970237732\n","Accuracy = 0.7857142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.06693239510059357\n","Accuracy = 0.7821428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.0041960752569139\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.003977739717811346\n","Accuracy = 0.7642857142857142\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7584229111671448\n","Accuracy = 0.55\n","Epoch: 2 of 8\n","bi=0, loss=0.6340844035148621\n","Accuracy = 0.6857142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.5620490908622742\n","Accuracy = 0.7178571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.3474940061569214\n","Accuracy = 0.7357142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.2548069953918457\n","Accuracy = 0.7214285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.2699029743671417\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.07661581039428711\n","Accuracy = 0.75\n","Epoch: 8 of 8\n","bi=0, loss=0.04517512768507004\n","Accuracy = 0.7607142857142857\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.73188716173172\n","Accuracy = 0.6785714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6081989407539368\n","Accuracy = 0.775\n","Epoch: 3 of 8\n","bi=0, loss=0.4909873306751251\n","Accuracy = 0.8035714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.16708128154277802\n","Accuracy = 0.7178571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.24700917303562164\n","Accuracy = 0.7857142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.04897601529955864\n","Accuracy = 0.7892857142857144\n","Epoch: 7 of 8\n","bi=0, loss=0.041252829134464264\n","Accuracy = 0.8035714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.008549757301807404\n","Accuracy = 0.7964285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7107480764389038\n","Accuracy = 0.5892857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.6677051782608032\n","Accuracy = 0.7035714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.6113971471786499\n","Accuracy = 0.725\n","Epoch: 4 of 8\n","bi=0, loss=0.5213348269462585\n","Accuracy = 0.725\n","Epoch: 5 of 8\n","bi=0, loss=0.44663292169570923\n","Accuracy = 0.7642857142857142\n","Epoch: 6 of 8\n","bi=0, loss=0.36225923895835876\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.2802901268005371\n","Accuracy = 0.7964285714285715\n","Epoch: 8 of 8\n","bi=0, loss=0.1596967875957489\n","Accuracy = 0.7857142857142858\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.734194278717041\n","Accuracy = 0.6178571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7021152973175049\n","Accuracy = 0.6464285714285715\n","Epoch: 3 of 8\n","bi=0, loss=0.6564632058143616\n","Accuracy = 0.7285714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.5240694880485535\n","Accuracy = 0.75\n","Epoch: 5 of 8\n","bi=0, loss=0.5544900894165039\n","Accuracy = 0.7571428571428571\n","Epoch: 6 of 8\n","bi=0, loss=0.3599422872066498\n","Accuracy = 0.7821428571428573\n","Epoch: 7 of 8\n","bi=0, loss=0.26348361372947693\n","Accuracy = 0.7928571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.25389784574508667\n","Accuracy = 0.7892857142857144\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6696865558624268\n","Accuracy = 0.5821428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6177524924278259\n","Accuracy = 0.6178571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.5792725682258606\n","Accuracy = 0.6857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.4783625304698944\n","Accuracy = 0.7107142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.34971457719802856\n","Accuracy = 0.7535714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.28025558590888977\n","Accuracy = 0.7785714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.21649400889873505\n","Accuracy = 0.7678571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.16268345713615417\n","Accuracy = 0.7785714285714287\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6783586740493774\n","Accuracy = 0.6\n","Epoch: 2 of 8\n","bi=0, loss=0.6099357604980469\n","Accuracy = 0.6821428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.6031714081764221\n","Accuracy = 0.7214285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.5060685873031616\n","Accuracy = 0.7464285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.4943847954273224\n","Accuracy = 0.775\n","Epoch: 6 of 8\n","bi=0, loss=0.40429773926734924\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.3327355682849884\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.2625519037246704\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7039778828620911\n","Accuracy = 0.5285714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6622336506843567\n","Accuracy = 0.6\n","Epoch: 3 of 8\n","bi=0, loss=0.5912922620773315\n","Accuracy = 0.725\n","Epoch: 4 of 8\n","bi=0, loss=0.5503950715065002\n","Accuracy = 0.7214285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.5396454334259033\n","Accuracy = 0.7607142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.39534011483192444\n","Accuracy = 0.7678571428571428\n","Epoch: 7 of 8\n","bi=0, loss=0.32288530468940735\n","Accuracy = 0.7892857142857144\n","Epoch: 8 of 8\n","bi=0, loss=0.20278304815292358\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7516173720359802\n","Accuracy = 0.5214285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6930293440818787\n","Accuracy = 0.6321428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.6757138967514038\n","Accuracy = 0.6214285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.580555260181427\n","Accuracy = 0.7071428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.5175915956497192\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.43120166659355164\n","Accuracy = 0.7357142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.42934370040893555\n","Accuracy = 0.7428571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.2841610908508301\n","Accuracy = 0.7678571428571428\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7508322596549988\n","Accuracy = 0.6035714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6576234698295593\n","Accuracy = 0.6642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.6346039175987244\n","Accuracy = 0.6892857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.5907987952232361\n","Accuracy = 0.7607142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.5239661931991577\n","Accuracy = 0.7678571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.46090880036354065\n","Accuracy = 0.7571428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.3822825253009796\n","Accuracy = 0.7607142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.33352014422416687\n","Accuracy = 0.7964285714285715\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7093284130096436\n","Accuracy = 0.5321428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6529598832130432\n","Accuracy = 0.6607142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.624078094959259\n","Accuracy = 0.7178571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.5611215829849243\n","Accuracy = 0.7535714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.4979863464832306\n","Accuracy = 0.8035714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.3232315480709076\n","Accuracy = 0.8035714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.2553602159023285\n","Accuracy = 0.8035714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.18889835476875305\n","Accuracy = 0.7892857142857144\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.756084144115448\n","Accuracy = 0.47857142857142854\n","Epoch: 2 of 8\n","bi=0, loss=0.744658887386322\n","Accuracy = 0.5357142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6634819507598877\n","Accuracy = 0.5357142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.6046396493911743\n","Accuracy = 0.7\n","Epoch: 5 of 8\n","bi=0, loss=0.5700068473815918\n","Accuracy = 0.7214285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.5026454329490662\n","Accuracy = 0.7321428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.37524357438087463\n","Accuracy = 0.7321428571428572\n","Epoch: 8 of 8\n","bi=0, loss=0.3192729949951172\n","Accuracy = 0.7428571428571429\n","parameters: Bertmodel: EnglishBert, Output: hidden, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7264255285263062\n","Accuracy = 0.5535714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6475576162338257\n","Accuracy = 0.6285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.6335462331771851\n","Accuracy = 0.7464285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.4894973635673523\n","Accuracy = 0.7571428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.3924373686313629\n","Accuracy = 0.7892857142857144\n","Epoch: 6 of 8\n","bi=0, loss=0.3292466402053833\n","Accuracy = 0.8035714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.19214598834514618\n","Accuracy = 0.775\n","Epoch: 8 of 8\n","bi=0, loss=0.17074985802173615\n","Accuracy = 0.8\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.687239408493042\n","Accuracy = 0.5571428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.681995689868927\n","Accuracy = 0.7142857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.5164796113967896\n","Accuracy = 0.7571428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.3297155499458313\n","Accuracy = 0.7928571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.2702513337135315\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.15806756913661957\n","Accuracy = 0.7785714285714287\n","Epoch: 7 of 8\n","bi=0, loss=0.049593016505241394\n","Accuracy = 0.7642857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.06090342253446579\n","Accuracy = 0.7642857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7391035556793213\n","Accuracy = 0.5678571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7237467169761658\n","Accuracy = 0.7357142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.5390051007270813\n","Accuracy = 0.7785714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.347627729177475\n","Accuracy = 0.7678571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.21748439967632294\n","Accuracy = 0.7892857142857144\n","Epoch: 6 of 8\n","bi=0, loss=0.20194953680038452\n","Accuracy = 0.7714285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.10404877364635468\n","Accuracy = 0.775\n","Epoch: 8 of 8\n","bi=0, loss=0.17730067670345306\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.667032778263092\n","Accuracy = 0.5071428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6662305593490601\n","Accuracy = 0.6571428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.583499550819397\n","Accuracy = 0.7321428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.3359001576900482\n","Accuracy = 0.7428571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.22471852600574493\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.1461719125509262\n","Accuracy = 0.7821428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.1320490539073944\n","Accuracy = 0.7892857142857144\n","Epoch: 8 of 8\n","bi=0, loss=0.15669940412044525\n","Accuracy = 0.7642857142857142\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7585351467132568\n","Accuracy = 0.625\n","Epoch: 2 of 8\n","bi=0, loss=0.6471230983734131\n","Accuracy = 0.6964285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.47690361738204956\n","Accuracy = 0.7642857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.36151123046875\n","Accuracy = 0.7785714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.27724021673202515\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.2254818230867386\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.07991892099380493\n","Accuracy = 0.7642857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.04165895655751228\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7425252795219421\n","Accuracy = 0.6821428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.6672170162200928\n","Accuracy = 0.7285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.6503995060920715\n","Accuracy = 0.7571428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.38540616631507874\n","Accuracy = 0.7964285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.2567281424999237\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.14821459352970123\n","Accuracy = 0.7892857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.15614132583141327\n","Accuracy = 0.7785714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.12412314116954803\n","Accuracy = 0.7928571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7282797694206238\n","Accuracy = 0.5464285714285715\n","Epoch: 2 of 8\n","bi=0, loss=0.7478250861167908\n","Accuracy = 0.6821428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.686025857925415\n","Accuracy = 0.7214285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.5031864047050476\n","Accuracy = 0.7357142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.30565640330314636\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.2599979639053345\n","Accuracy = 0.7321428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.20324887335300446\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.1727815568447113\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8380948305130005\n","Accuracy = 0.6464285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6873462796211243\n","Accuracy = 0.7285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.6185654997825623\n","Accuracy = 0.7642857142857142\n","Epoch: 4 of 8\n","bi=0, loss=0.4561927914619446\n","Accuracy = 0.7428571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.42077597975730896\n","Accuracy = 0.7892857142857144\n","Epoch: 6 of 8\n","bi=0, loss=0.24722711741924286\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.1733214110136032\n","Accuracy = 0.7535714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.12688283622264862\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7559704184532166\n","Accuracy = 0.6035714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.6571272015571594\n","Accuracy = 0.7178571428571429\n","Epoch: 3 of 8\n","bi=0, loss=0.6578404903411865\n","Accuracy = 0.75\n","Epoch: 4 of 8\n","bi=0, loss=0.44611361622810364\n","Accuracy = 0.7642857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.39735496044158936\n","Accuracy = 0.7892857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.19807684421539307\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.18367791175842285\n","Accuracy = 0.7857142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.059275928884744644\n","Accuracy = 0.7642857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8020824193954468\n","Accuracy = 0.5928571428571427\n","Epoch: 2 of 8\n","bi=0, loss=0.6716513633728027\n","Accuracy = 0.6464285714285715\n","Epoch: 3 of 8\n","bi=0, loss=0.6292530298233032\n","Accuracy = 0.7142857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.48663127422332764\n","Accuracy = 0.7250000000000001\n","Epoch: 5 of 8\n","bi=0, loss=0.3380890190601349\n","Accuracy = 0.75\n","Epoch: 6 of 8\n","bi=0, loss=0.19329336285591125\n","Accuracy = 0.75\n","Epoch: 7 of 8\n","bi=0, loss=0.13332577049732208\n","Accuracy = 0.7321428571428572\n","Epoch: 8 of 8\n","bi=0, loss=0.17523646354675293\n","Accuracy = 0.7285714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7606812119483948\n","Accuracy = 0.6035714285714285\n","Epoch: 2 of 8\n","bi=0, loss=0.6848148703575134\n","Accuracy = 0.7107142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.5787473917007446\n","Accuracy = 0.7392857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.458092600107193\n","Accuracy = 0.775\n","Epoch: 5 of 8\n","bi=0, loss=0.2217913717031479\n","Accuracy = 0.7928571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.17305418848991394\n","Accuracy = 0.7928571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.05676509439945221\n","Accuracy = 0.7785714285714287\n","Epoch: 8 of 8\n","bi=0, loss=0.0412561409175396\n","Accuracy = 0.7857142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6929275989532471\n","Accuracy = 0.5392857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.7175261378288269\n","Accuracy = 0.5785714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.6840195655822754\n","Accuracy = 0.6821428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.6576607823371887\n","Accuracy = 0.7035714285714285\n","Epoch: 5 of 8\n","bi=0, loss=0.5924468040466309\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.47390085458755493\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.42823514342308044\n","Accuracy = 0.7642857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.3743901252746582\n","Accuracy = 0.7714285714285714\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6958778500556946\n","Accuracy = 0.6\n","Epoch: 2 of 8\n","bi=0, loss=0.6795697808265686\n","Accuracy = 0.6535714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.6873908042907715\n","Accuracy = 0.7464285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.6014946699142456\n","Accuracy = 0.7678571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.5606687068939209\n","Accuracy = 0.7678571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.4536614418029785\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.41209933161735535\n","Accuracy = 0.7428571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.41077640652656555\n","Accuracy = 0.7428571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7065565586090088\n","Accuracy = 0.5321428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.7096579670906067\n","Accuracy = 0.5214285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.6836380362510681\n","Accuracy = 0.6499999999999999\n","Epoch: 4 of 8\n","bi=0, loss=0.6122263669967651\n","Accuracy = 0.7035714285714285\n","Epoch: 5 of 8\n","bi=0, loss=0.5350055694580078\n","Accuracy = 0.7071428571428571\n","Epoch: 6 of 8\n","bi=0, loss=0.45832207798957825\n","Accuracy = 0.7428571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.39648643136024475\n","Accuracy = 0.7464285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.28663262724876404\n","Accuracy = 0.7571428571428571\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7562235593795776\n","Accuracy = 0.5428571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.6811295747756958\n","Accuracy = 0.5892857142857142\n","Epoch: 3 of 8\n","bi=0, loss=0.6643525958061218\n","Accuracy = 0.6714285714285715\n","Epoch: 4 of 8\n","bi=0, loss=0.6457440257072449\n","Accuracy = 0.6714285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.5957556366920471\n","Accuracy = 0.7142857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.5290274024009705\n","Accuracy = 0.75\n","Epoch: 7 of 8\n","bi=0, loss=0.4868997037410736\n","Accuracy = 0.7535714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.4178433418273926\n","Accuracy = 0.7678571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7613120675086975\n","Accuracy = 0.5642857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.7249585390090942\n","Accuracy = 0.6607142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6557693481445312\n","Accuracy = 0.7107142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.6013485789299011\n","Accuracy = 0.725\n","Epoch: 5 of 8\n","bi=0, loss=0.5556939840316772\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.4710082709789276\n","Accuracy = 0.7464285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.3548879325389862\n","Accuracy = 0.8\n","Epoch: 8 of 8\n","bi=0, loss=0.3417181372642517\n","Accuracy = 0.7857142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7622276544570923\n","Accuracy = 0.5535714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.688604474067688\n","Accuracy = 0.5571428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.6640370488166809\n","Accuracy = 0.6535714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.6632537245750427\n","Accuracy = 0.6785714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.6444633603096008\n","Accuracy = 0.6821428571428572\n","Epoch: 6 of 8\n","bi=0, loss=0.5728753805160522\n","Accuracy = 0.6928571428571428\n","Epoch: 7 of 8\n","bi=0, loss=0.5032987594604492\n","Accuracy = 0.7035714285714285\n","Epoch: 8 of 8\n","bi=0, loss=0.44879597425460815\n","Accuracy = 0.7\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7351225018501282\n","Accuracy = 0.5428571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.6854724287986755\n","Accuracy = 0.6607142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.7049147486686707\n","Accuracy = 0.7071428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.6578047871589661\n","Accuracy = 0.725\n","Epoch: 5 of 8\n","bi=0, loss=0.6510984897613525\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.558007001876831\n","Accuracy = 0.7321428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.5334938764572144\n","Accuracy = 0.7714285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.455175518989563\n","Accuracy = 0.7714285714285716\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7404348254203796\n","Accuracy = 0.5892857142857142\n","Epoch: 2 of 8\n","bi=0, loss=0.6897376775741577\n","Accuracy = 0.5642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.6706151366233826\n","Accuracy = 0.6071428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.6349807381629944\n","Accuracy = 0.6464285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.6596052646636963\n","Accuracy = 0.6928571428571428\n","Epoch: 6 of 8\n","bi=0, loss=0.5694906115531921\n","Accuracy = 0.7035714285714285\n","Epoch: 7 of 8\n","bi=0, loss=0.5783510208129883\n","Accuracy = 0.7464285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.4836811423301697\n","Accuracy = 0.7321428571428572\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7491035461425781\n","Accuracy = 0.5642857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.7012237906455994\n","Accuracy = 0.5714285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.7108712792396545\n","Accuracy = 0.6321428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.6892172694206238\n","Accuracy = 0.6285714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.6557958126068115\n","Accuracy = 0.675\n","Epoch: 6 of 8\n","bi=0, loss=0.6116611957550049\n","Accuracy = 0.6964285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.5691805481910706\n","Accuracy = 0.7071428571428572\n","Epoch: 8 of 8\n","bi=0, loss=0.4570588767528534\n","Accuracy = 0.7035714285714285\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 2e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7691090106964111\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.6439577341079712\n","Accuracy = 0.5642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.6718773245811462\n","Accuracy = 0.6178571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.6515918374061584\n","Accuracy = 0.7214285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.6420100927352905\n","Accuracy = 0.7464285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.595055103302002\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.5076124668121338\n","Accuracy = 0.7678571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.42717188596725464\n","Accuracy = 0.7607142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.687239408493042\n","Accuracy = 0.5428571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.6972494721412659\n","Accuracy = 0.7321428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.5417874455451965\n","Accuracy = 0.7642857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.3103379011154175\n","Accuracy = 0.7607142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.2596129775047302\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.14402614533901215\n","Accuracy = 0.7571428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.01866604946553707\n","Accuracy = 0.7607142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.013153860345482826\n","Accuracy = 0.75\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7391035556793213\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.7255486249923706\n","Accuracy = 0.7357142857142858\n","Epoch: 3 of 8\n","bi=0, loss=0.5880097150802612\n","Accuracy = 0.7892857142857144\n","Epoch: 4 of 8\n","bi=0, loss=0.3657117187976837\n","Accuracy = 0.7892857142857144\n","Epoch: 5 of 8\n","bi=0, loss=0.12493408471345901\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.21410050988197327\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.03166721388697624\n","Accuracy = 0.7607142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.026554344221949577\n","Accuracy = 0.7642857142857142\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.667032778263092\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.7150003910064697\n","Accuracy = 0.7071428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.5573803782463074\n","Accuracy = 0.7857142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.19965951144695282\n","Accuracy = 0.7785714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.18235506117343903\n","Accuracy = 0.7857142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.0934407040476799\n","Accuracy = 0.7428571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.11371516436338425\n","Accuracy = 0.7821428571428573\n","Epoch: 8 of 8\n","bi=0, loss=0.030157420784235\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7585351467132568\n","Accuracy = 0.5392857142857143\n","Epoch: 2 of 8\n","bi=0, loss=0.6578436493873596\n","Accuracy = 0.717857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.5251575708389282\n","Accuracy = 0.7821428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.3281576633453369\n","Accuracy = 0.7892857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.23614631593227386\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.1817501187324524\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.060758691281080246\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.04403291642665863\n","Accuracy = 0.7678571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7425252795219421\n","Accuracy = 0.7035714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6551700830459595\n","Accuracy = 0.7321428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.5979520082473755\n","Accuracy = 0.7678571428571429\n","Epoch: 4 of 8\n","bi=0, loss=0.39937424659729004\n","Accuracy = 0.7892857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.21306021511554718\n","Accuracy = 0.7607142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.13347351551055908\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.10493248701095581\n","Accuracy = 0.7642857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.07084539532661438\n","Accuracy = 0.7857142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7282797694206238\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.7409548759460449\n","Accuracy = 0.6928571428571428\n","Epoch: 3 of 8\n","bi=0, loss=0.6394643783569336\n","Accuracy = 0.7214285714285715\n","Epoch: 4 of 8\n","bi=0, loss=0.47077062726020813\n","Accuracy = 0.7107142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.4366583824157715\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.3096338212490082\n","Accuracy = 0.7178571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.14839854836463928\n","Accuracy = 0.7357142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.17032907903194427\n","Accuracy = 0.725\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8380948305130005\n","Accuracy = 0.575\n","Epoch: 2 of 8\n","bi=0, loss=0.6708924770355225\n","Accuracy = 0.7464285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.5640615224838257\n","Accuracy = 0.7535714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.48584237694740295\n","Accuracy = 0.775\n","Epoch: 5 of 8\n","bi=0, loss=0.30047568678855896\n","Accuracy = 0.7607142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.19097116589546204\n","Accuracy = 0.7571428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.09939511865377426\n","Accuracy = 0.7714285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.04936239495873451\n","Accuracy = 0.7571428571428571\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7559704184532166\n","Accuracy = 0.5321428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.6530731916427612\n","Accuracy = 0.7392857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.6260577440261841\n","Accuracy = 0.7035714285714285\n","Epoch: 4 of 8\n","bi=0, loss=0.5393158793449402\n","Accuracy = 0.7821428571428573\n","Epoch: 5 of 8\n","bi=0, loss=0.36114001274108887\n","Accuracy = 0.7678571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.20110918581485748\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.09689562767744064\n","Accuracy = 0.7714285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.1118014007806778\n","Accuracy = 0.7892857142857144\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8020824193954468\n","Accuracy = 0.5428571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.6737586259841919\n","Accuracy = 0.6857142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.5670720338821411\n","Accuracy = 0.725\n","Epoch: 4 of 8\n","bi=0, loss=0.5086271166801453\n","Accuracy = 0.7571428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.3221869170665741\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.1480003446340561\n","Accuracy = 0.7321428571428572\n","Epoch: 7 of 8\n","bi=0, loss=0.1294560730457306\n","Accuracy = 0.7321428571428572\n","Epoch: 8 of 8\n","bi=0, loss=0.030026210471987724\n","Accuracy = 0.7392857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7606812119483948\n","Accuracy = 0.5571428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.6870854496955872\n","Accuracy = 0.7071428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.6163488626480103\n","Accuracy = 0.7571428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.5507778525352478\n","Accuracy = 0.7892857142857144\n","Epoch: 5 of 8\n","bi=0, loss=0.2103159874677658\n","Accuracy = 0.7678571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.071917824447155\n","Accuracy = 0.7750000000000001\n","Epoch: 7 of 8\n","bi=0, loss=0.038417138159275055\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.014782794751226902\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6929275989532471\n","Accuracy = 0.4892857142857142\n","Epoch: 2 of 8\n","bi=0, loss=0.7275680303573608\n","Accuracy = 0.5678571428571428\n","Epoch: 3 of 8\n","bi=0, loss=0.6892668604850769\n","Accuracy = 0.6642857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.6687767505645752\n","Accuracy = 0.7\n","Epoch: 5 of 8\n","bi=0, loss=0.5950470566749573\n","Accuracy = 0.7357142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.4803156554698944\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.3545706272125244\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.24999721348285675\n","Accuracy = 0.775\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6958778500556946\n","Accuracy = 0.5678571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.6921381950378418\n","Accuracy = 0.5785714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.703161895275116\n","Accuracy = 0.7142857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.6396009922027588\n","Accuracy = 0.7571428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.5873493552207947\n","Accuracy = 0.7785714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.47722887992858887\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.3709218204021454\n","Accuracy = 0.7535714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.33863750100135803\n","Accuracy = 0.7607142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7065565586090088\n","Accuracy = 0.5464285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.7009778022766113\n","Accuracy = 0.5142857142857142\n","Epoch: 3 of 8\n","bi=0, loss=0.6953336596488953\n","Accuracy = 0.5785714285714285\n","Epoch: 4 of 8\n","bi=0, loss=0.6244984269142151\n","Accuracy = 0.6714285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.5690126419067383\n","Accuracy = 0.7107142857142857\n","Epoch: 6 of 8\n","bi=0, loss=0.4859222173690796\n","Accuracy = 0.7428571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.3872694969177246\n","Accuracy = 0.7142857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.28274476528167725\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7562235593795776\n","Accuracy = 0.4892857142857142\n","Epoch: 2 of 8\n","bi=0, loss=0.6858633756637573\n","Accuracy = 0.5571428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.665727972984314\n","Accuracy = 0.675\n","Epoch: 4 of 8\n","bi=0, loss=0.6557413339614868\n","Accuracy = 0.6821428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.61674964427948\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.5312029123306274\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.5005030035972595\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.4166800081729889\n","Accuracy = 0.7642857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7613120675086975\n","Accuracy = 0.5071428571428571\n","Epoch: 2 of 8\n","bi=0, loss=0.7314859628677368\n","Accuracy = 0.6321428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.670332670211792\n","Accuracy = 0.6857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.6523833870887756\n","Accuracy = 0.717857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.5895076394081116\n","Accuracy = 0.75\n","Epoch: 6 of 8\n","bi=0, loss=0.5546825528144836\n","Accuracy = 0.7678571428571428\n","Epoch: 7 of 8\n","bi=0, loss=0.3874446451663971\n","Accuracy = 0.775\n","Epoch: 8 of 8\n","bi=0, loss=0.30990928411483765\n","Accuracy = 0.7964285714285715\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7622276544570923\n","Accuracy = 0.5035714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6942849159240723\n","Accuracy = 0.5321428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.6672747731208801\n","Accuracy = 0.6428571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.6678987741470337\n","Accuracy = 0.6821428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.672999918460846\n","Accuracy = 0.7\n","Epoch: 6 of 8\n","bi=0, loss=0.557858943939209\n","Accuracy = 0.7107142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.5110357999801636\n","Accuracy = 0.7071428571428572\n","Epoch: 8 of 8\n","bi=0, loss=0.44576799869537354\n","Accuracy = 0.7071428571428572\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7351225018501282\n","Accuracy = 0.5178571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.6945403218269348\n","Accuracy = 0.6285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.7105138301849365\n","Accuracy = 0.7357142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.6783117055892944\n","Accuracy = 0.6714285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.668325662612915\n","Accuracy = 0.7464285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.588907778263092\n","Accuracy = 0.7357142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.5324442982673645\n","Accuracy = 0.7678571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.4671251177787781\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7404348254203796\n","Accuracy = 0.5857142857142856\n","Epoch: 2 of 8\n","bi=0, loss=0.7007467150688171\n","Accuracy = 0.5464285714285714\n","Epoch: 3 of 8\n","bi=0, loss=0.6956166625022888\n","Accuracy = 0.6214285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.6564233899116516\n","Accuracy = 0.675\n","Epoch: 5 of 8\n","bi=0, loss=0.6742292046546936\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.574209451675415\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.5208205580711365\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.4658281207084656\n","Accuracy = 0.7821428571428573\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7491035461425781\n","Accuracy = 0.5178571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7056033611297607\n","Accuracy = 0.5357142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.7100886106491089\n","Accuracy = 0.6428571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.6882489323616028\n","Accuracy = 0.6392857142857142\n","Epoch: 5 of 8\n","bi=0, loss=0.6478899717330933\n","Accuracy = 0.6821428571428572\n","Epoch: 6 of 8\n","bi=0, loss=0.6250560283660889\n","Accuracy = 0.7107142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.5069954991340637\n","Accuracy = 0.7107142857142856\n","Epoch: 8 of 8\n","bi=0, loss=0.3979516625404358\n","Accuracy = 0.725\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 3e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7691090106964111\n","Accuracy = 0.4964285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.6467171311378479\n","Accuracy = 0.5285714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.6752058863639832\n","Accuracy = 0.6571428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.6601476073265076\n","Accuracy = 0.7035714285714286\n","Epoch: 5 of 8\n","bi=0, loss=0.645673394203186\n","Accuracy = 0.7178571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.5764610767364502\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.516175389289856\n","Accuracy = 0.75\n","Epoch: 8 of 8\n","bi=0, loss=0.42600712180137634\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.687239408493042\n","Accuracy = 0.5714285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.701785683631897\n","Accuracy = 0.6785714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.626305341720581\n","Accuracy = 0.7642857142857142\n","Epoch: 4 of 8\n","bi=0, loss=0.4357512593269348\n","Accuracy = 0.7642857142857142\n","Epoch: 5 of 8\n","bi=0, loss=0.27197691798210144\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.18531595170497894\n","Accuracy = 0.7857142857142858\n","Epoch: 7 of 8\n","bi=0, loss=0.111412912607193\n","Accuracy = 0.7642857142857142\n","Epoch: 8 of 8\n","bi=0, loss=0.021553829312324524\n","Accuracy = 0.7892857142857144\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7391035556793213\n","Accuracy = 0.5285714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.7270406484603882\n","Accuracy = 0.7285714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.3666565716266632\n","Accuracy = 0.7678571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.21656596660614014\n","Accuracy = 0.775\n","Epoch: 5 of 8\n","bi=0, loss=0.10779134929180145\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.10427745431661606\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.016598062589764595\n","Accuracy = 0.7857142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.014939229935407639\n","Accuracy = 0.7857142857142858\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.667032778263092\n","Accuracy = 0.5214285714285714\n","Epoch: 2 of 8\n","bi=0, loss=0.7454373240470886\n","Accuracy = 0.7\n","Epoch: 3 of 8\n","bi=0, loss=0.5439749360084534\n","Accuracy = 0.7464285714285714\n","Epoch: 4 of 8\n","bi=0, loss=0.14789150655269623\n","Accuracy = 0.7749999999999999\n","Epoch: 5 of 8\n","bi=0, loss=0.27952471375465393\n","Accuracy = 0.7428571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.08862550556659698\n","Accuracy = 0.7535714285714286\n","Epoch: 7 of 8\n","bi=0, loss=0.06953030079603195\n","Accuracy = 0.7642857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.02558591403067112\n","Accuracy = 0.7464285714285714\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7585351467132568\n","Accuracy = 0.525\n","Epoch: 2 of 8\n","bi=0, loss=0.6707178950309753\n","Accuracy = 0.7\n","Epoch: 3 of 8\n","bi=0, loss=0.5448802709579468\n","Accuracy = 0.7821428571428571\n","Epoch: 4 of 8\n","bi=0, loss=0.36627480387687683\n","Accuracy = 0.7821428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.277047336101532\n","Accuracy = 0.7607142857142858\n","Epoch: 6 of 8\n","bi=0, loss=0.1559785157442093\n","Accuracy = 0.7714285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.12727157771587372\n","Accuracy = 0.7678571428571428\n","Epoch: 8 of 8\n","bi=0, loss=0.020125992596149445\n","Accuracy = 0.7928571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7425252795219421\n","Accuracy = 0.6821428571428572\n","Epoch: 2 of 8\n","bi=0, loss=0.6901536583900452\n","Accuracy = 0.6857142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6731109619140625\n","Accuracy = 0.7857142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.5160166025161743\n","Accuracy = 0.7642857142857143\n","Epoch: 5 of 8\n","bi=0, loss=0.34785908460617065\n","Accuracy = 0.7785714285714287\n","Epoch: 6 of 8\n","bi=0, loss=0.2348102480173111\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.1585773378610611\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.19880977272987366\n","Accuracy = 0.7642857142857142\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7282797694206238\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.7029029726982117\n","Accuracy = 0.7107142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.6198310852050781\n","Accuracy = 0.7285714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.3065725564956665\n","Accuracy = 0.7357142857142858\n","Epoch: 5 of 8\n","bi=0, loss=0.20445555448532104\n","Accuracy = 0.7392857142857143\n","Epoch: 6 of 8\n","bi=0, loss=0.3325647711753845\n","Accuracy = 0.7250000000000001\n","Epoch: 7 of 8\n","bi=0, loss=0.1207621842622757\n","Accuracy = 0.7214285714285714\n","Epoch: 8 of 8\n","bi=0, loss=0.04574521631002426\n","Accuracy = 0.7428571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8380948305130005\n","Accuracy = 0.5285714285714286\n","Epoch: 2 of 8\n","bi=0, loss=0.6712012887001038\n","Accuracy = 0.7571428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.5894971489906311\n","Accuracy = 0.75\n","Epoch: 4 of 8\n","bi=0, loss=0.5114291906356812\n","Accuracy = 0.7821428571428571\n","Epoch: 5 of 8\n","bi=0, loss=0.23722782731056213\n","Accuracy = 0.7714285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.14990974962711334\n","Accuracy = 0.7642857142857142\n","Epoch: 7 of 8\n","bi=0, loss=0.0349339097738266\n","Accuracy = 0.7607142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.0771774873137474\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7559704184532166\n","Accuracy = 0.5178571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.6775738000869751\n","Accuracy = 0.7571428571428571\n","Epoch: 3 of 8\n","bi=0, loss=0.6236109733581543\n","Accuracy = 0.7892857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.3891238272190094\n","Accuracy = 0.7250000000000001\n","Epoch: 5 of 8\n","bi=0, loss=0.3367159068584442\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.10821106284856796\n","Accuracy = 0.8178571428571428\n","Epoch: 7 of 8\n","bi=0, loss=0.03404034674167633\n","Accuracy = 0.7535714285714286\n","Epoch: 8 of 8\n","bi=0, loss=0.030458206310868263\n","Accuracy = 0.7928571428571429\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.8020824193954468\n","Accuracy = 0.5249999999999999\n","Epoch: 2 of 8\n","bi=0, loss=0.6860429644584656\n","Accuracy = 0.6785714285714286\n","Epoch: 3 of 8\n","bi=0, loss=0.5869295001029968\n","Accuracy = 0.7107142857142857\n","Epoch: 4 of 8\n","bi=0, loss=0.5190280675888062\n","Accuracy = 0.7428571428571429\n","Epoch: 5 of 8\n","bi=0, loss=0.3169311583042145\n","Accuracy = 0.7464285714285714\n","Epoch: 6 of 8\n","bi=0, loss=0.1797247678041458\n","Accuracy = 0.7214285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.04083695262670517\n","Accuracy = 0.7607142857142858\n","Epoch: 8 of 8\n","bi=0, loss=0.05242682993412018\n","Accuracy = 0.725\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 32, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 77, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7606812119483948\n","Accuracy = 0.6107142857142858\n","Epoch: 2 of 8\n","bi=0, loss=0.7236505150794983\n","Accuracy = 0.7250000000000001\n","Epoch: 3 of 8\n","bi=0, loss=0.5685921311378479\n","Accuracy = 0.7857142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.2832880914211273\n","Accuracy = 0.7714285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.1809103637933731\n","Accuracy = 0.7928571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.06021706387400627\n","Accuracy = 0.7892857142857144\n","Epoch: 7 of 8\n","bi=0, loss=0.05640292540192604\n","Accuracy = 0.7928571428571428\n","Epoch: 8 of 8\n","bi=0, loss=0.013870345428586006\n","Accuracy = 0.7892857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 1\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6929275989532471\n","Accuracy = 0.525\n","Epoch: 2 of 8\n","bi=0, loss=0.731982409954071\n","Accuracy = 0.5821428571428572\n","Epoch: 3 of 8\n","bi=0, loss=0.6996458172798157\n","Accuracy = 0.7000000000000001\n","Epoch: 4 of 8\n","bi=0, loss=0.6594224572181702\n","Accuracy = 0.7214285714285715\n","Epoch: 5 of 8\n","bi=0, loss=0.5754457712173462\n","Accuracy = 0.7714285714285715\n","Epoch: 6 of 8\n","bi=0, loss=0.42516428232192993\n","Accuracy = 0.7642857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.3148811161518097\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.20223839581012726\n","Accuracy = 0.7714285714285715\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 2\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.6958778500556946\n","Accuracy = 0.5678571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.6934790015220642\n","Accuracy = 0.6392857142857142\n","Epoch: 3 of 8\n","bi=0, loss=0.6904610991477966\n","Accuracy = 0.7357142857142858\n","Epoch: 4 of 8\n","bi=0, loss=0.6162733435630798\n","Accuracy = 0.775\n","Epoch: 5 of 8\n","bi=0, loss=0.5215407013893127\n","Accuracy = 0.7785714285714287\n","Epoch: 6 of 8\n","bi=0, loss=0.3152003586292267\n","Accuracy = 0.7714285714285715\n","Epoch: 7 of 8\n","bi=0, loss=0.29458075761795044\n","Accuracy = 0.7964285714285715\n","Epoch: 8 of 8\n","bi=0, loss=0.23035980761051178\n","Accuracy = 0.7642857142857143\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 3\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7065565586090088\n","Accuracy = 0.5178571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.7087948322296143\n","Accuracy = 0.5642857142857143\n","Epoch: 3 of 8\n","bi=0, loss=0.6815981268882751\n","Accuracy = 0.6821428571428572\n","Epoch: 4 of 8\n","bi=0, loss=0.604636013507843\n","Accuracy = 0.7214285714285714\n","Epoch: 5 of 8\n","bi=0, loss=0.44409412145614624\n","Accuracy = 0.7678571428571428\n","Epoch: 6 of 8\n","bi=0, loss=0.3314669728279114\n","Accuracy = 0.775\n","Epoch: 7 of 8\n","bi=0, loss=0.28585284948349\n","Accuracy = 0.7821428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.21070630848407745\n","Accuracy = 0.7535714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 4\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7562235593795776\n","Accuracy = 0.475\n","Epoch: 2 of 8\n","bi=0, loss=0.6904255151748657\n","Accuracy = 0.525\n","Epoch: 3 of 8\n","bi=0, loss=0.6684809923171997\n","Accuracy = 0.6499999999999999\n","Epoch: 4 of 8\n","bi=0, loss=0.6648352742195129\n","Accuracy = 0.6928571428571428\n","Epoch: 5 of 8\n","bi=0, loss=0.5847687125205994\n","Accuracy = 0.7321428571428572\n","Epoch: 6 of 8\n","bi=0, loss=0.5464218854904175\n","Accuracy = 0.7392857142857143\n","Epoch: 7 of 8\n","bi=0, loss=0.5918574929237366\n","Accuracy = 0.7607142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.45275700092315674\n","Accuracy = 0.7607142857142857\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 5\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7613120675086975\n","Accuracy = 0.4928571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.7309288382530212\n","Accuracy = 0.5499999999999999\n","Epoch: 3 of 8\n","bi=0, loss=0.6751221418380737\n","Accuracy = 0.6785714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.6485214233398438\n","Accuracy = 0.7107142857142857\n","Epoch: 5 of 8\n","bi=0, loss=0.5681979060173035\n","Accuracy = 0.7642857142857142\n","Epoch: 6 of 8\n","bi=0, loss=0.4239453375339508\n","Accuracy = 0.7821428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.22012509405612946\n","Accuracy = 0.7571428571428571\n","Epoch: 8 of 8\n","bi=0, loss=0.1505810171365738\n","Accuracy = 0.7785714285714286\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 6\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7622276544570923\n","Accuracy = 0.4928571428571428\n","Epoch: 2 of 8\n","bi=0, loss=0.6955257654190063\n","Accuracy = 0.5249999999999999\n","Epoch: 3 of 8\n","bi=0, loss=0.6647566556930542\n","Accuracy = 0.6785714285714286\n","Epoch: 4 of 8\n","bi=0, loss=0.6509515047073364\n","Accuracy = 0.7071428571428572\n","Epoch: 5 of 8\n","bi=0, loss=0.608310878276825\n","Accuracy = 0.7178571428571429\n","Epoch: 6 of 8\n","bi=0, loss=0.48969972133636475\n","Accuracy = 0.7607142857142857\n","Epoch: 7 of 8\n","bi=0, loss=0.42766496539115906\n","Accuracy = 0.7142857142857143\n","Epoch: 8 of 8\n","bi=0, loss=0.33942633867263794\n","Accuracy = 0.7321428571428571\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 7\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7351225018501282\n","Accuracy = 0.4928571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.7015557885169983\n","Accuracy = 0.5357142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.7165188193321228\n","Accuracy = 0.6928571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.6838693618774414\n","Accuracy = 0.725\n","Epoch: 5 of 8\n","bi=0, loss=0.646981954574585\n","Accuracy = 0.775\n","Epoch: 6 of 8\n","bi=0, loss=0.5405582785606384\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.49466297030448914\n","Accuracy = 0.7678571428571428\n","Epoch: 8 of 8\n","bi=0, loss=0.47297611832618713\n","Accuracy = 0.7964285714285715\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 8\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7404348254203796\n","Accuracy = 0.5428571428571429\n","Epoch: 2 of 8\n","bi=0, loss=0.7095186710357666\n","Accuracy = 0.5357142857142857\n","Epoch: 3 of 8\n","bi=0, loss=0.7047456502914429\n","Accuracy = 0.6642857142857143\n","Epoch: 4 of 8\n","bi=0, loss=0.6438111662864685\n","Accuracy = 0.675\n","Epoch: 5 of 8\n","bi=0, loss=0.6451961398124695\n","Accuracy = 0.7535714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.5094869136810303\n","Accuracy = 0.7821428571428571\n","Epoch: 7 of 8\n","bi=0, loss=0.3942521810531616\n","Accuracy = 0.7928571428571429\n","Epoch: 8 of 8\n","bi=0, loss=0.2525215744972229\n","Accuracy = 0.7464285714285714\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 9\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7491035461425781\n","Accuracy = 0.47857142857142854\n","Epoch: 2 of 8\n","bi=0, loss=0.7221168279647827\n","Accuracy = 0.5285714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.7169677019119263\n","Accuracy = 0.6678571428571428\n","Epoch: 4 of 8\n","bi=0, loss=0.6559797525405884\n","Accuracy = 0.7035714285714285\n","Epoch: 5 of 8\n","bi=0, loss=0.625446617603302\n","Accuracy = 0.7285714285714286\n","Epoch: 6 of 8\n","bi=0, loss=0.4804634749889374\n","Accuracy = 0.7464285714285714\n","Epoch: 7 of 8\n","bi=0, loss=0.3166535496711731\n","Accuracy = 0.725\n","Epoch: 8 of 8\n","bi=0, loss=0.33829009532928467\n","Accuracy = 0.7321428571428572\n","parameters: Bertmodel: EnglishBert, Output: pooler, lr: 5e-05, Batch: 64, Totsl Num. Epochs: 8, Fold: 10\n","num_train_steps = 38, world_size=8\n","Epoch: 1 of 8\n","bi=0, loss=0.7691090106964111\n","Accuracy = 0.42499999999999993\n","Epoch: 2 of 8\n","bi=0, loss=0.6475314497947693\n","Accuracy = 0.5285714285714285\n","Epoch: 3 of 8\n","bi=0, loss=0.672462522983551\n","Accuracy = 0.7\n","Epoch: 4 of 8\n","bi=0, loss=0.656985878944397\n","Accuracy = 0.7250000000000001\n","Epoch: 5 of 8\n","bi=0, loss=0.6132516264915466\n","Accuracy = 0.7285714285714285\n","Epoch: 6 of 8\n","bi=0, loss=0.44370704889297485\n","Accuracy = 0.7678571428571429\n","Epoch: 7 of 8\n","bi=0, loss=0.36514344811439514\n","Accuracy = 0.7607142857142857\n","Epoch: 8 of 8\n","bi=0, loss=0.22372637689113617\n","Accuracy = 0.7749999999999999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hUbui2-D_FP3"},"source":["def AveragResults(FileName, Path):\n","  with open(Path + FileName + \".pkl\", \"rb\") as f:\n","              Results = pickle.load(f)\n","\n","  for BT, ModelBertType,  in Results.items():\n","    for OP, OutPut in ModelBertType.items():\n","      for LR, LearningRate in OutPut.items():\n","        for BS, BatchSize in LearningRate.items():\n","          for EP, Epoch in BatchSize.items():\n","            for Metrics, ValuesCrossValidation in  Epoch.items():\n"," \n","              # Metrics = np.mean(ValuesCrossValidation)\n","              Results[BT][OP][LR][BS][EP][Metrics] = np.mean(ValuesCrossValidation)\n","            \n","  with open('Average' + FileName + '.pkl','wb') as f:\n","    pickle.dump(Results, f)\n","\n","  with open(Path + 'Average' + FileName + '.pkl','wb') as f:\n","    pickle.dump(Results, f)\n","  \n","  return Results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNx5HL3gE1G9"},"source":["## Average and Save Results\n","AverageResultsTask = AveragResults(FileName=FileResults, Path=Path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Wm1dH5GgFDP"},"source":["### create dataframe for our results\n","def create_Data_Frame(all_resultas):\n","\n","  \n","\n","  ### Criate a pandas da Frame with all results\n","  df_results = pd.DataFrame.from_dict({(BertType, OutpuType, LearningRate, BactSize, Epochs): all_resultas[BertType][OutpuType][LearningRate][BactSize][Epochs]\n","                            for BertType in all_resultas.keys()\n","                            for OutpuType in all_resultas[BertType].keys()\n","                            for LearningRate in all_resultas[BertType][OutpuType].keys()\n","                            for BactSize in all_resultas[BertType][OutpuType][LearningRate].keys()\n","                            for Epochs in all_resultas[BertType][OutpuType][LearningRate][BactSize].keys()},\n","                        orient='index')\n","  return df_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_e1yqO24I3w4","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1619288902547,"user_tz":180,"elapsed":578,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"4930842c-8f86-42eb-9ab8-1f1e4fc6a322"},"source":["## Create a Data Frame\n","DfResultsTask = create_Data_Frame(all_resultas=AverageResultsTask)\n","\n","### save results to a CSV file\n","DfResultsTask.to_csv(Path + 'Average' + FileResults + '_CSV_' + '.csv')\n","\n","### See the Avarage results in the Pandas data Frame\n","DfResultsTask"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>recall</th>\n","      <th>precision</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"11\" valign=\"top\">EnglishBert</th>\n","      <th rowspan=\"5\" valign=\"top\">hidden</th>\n","      <th rowspan=\"5\" valign=\"top\">0.00002</th>\n","      <th rowspan=\"5\" valign=\"top\">32</th>\n","      <th>1</th>\n","      <td>0.632500</td>\n","      <td>0.517751</td>\n","      <td>0.459445</td>\n","      <td>0.686184</td>\n","      <td>0.718207</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.727500</td>\n","      <td>0.728819</td>\n","      <td>0.791426</td>\n","      <td>0.694697</td>\n","      <td>0.611783</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.760357</td>\n","      <td>0.738647</td>\n","      <td>0.739083</td>\n","      <td>0.754953</td>\n","      <td>0.504368</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.777500</td>\n","      <td>0.772462</td>\n","      <td>0.817220</td>\n","      <td>0.744135</td>\n","      <td>0.400660</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.777143</td>\n","      <td>0.757069</td>\n","      <td>0.755135</td>\n","      <td>0.778056</td>\n","      <td>0.284866</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">pooler</th>\n","      <th rowspan=\"5\" valign=\"top\">0.00005</th>\n","      <th rowspan=\"5\" valign=\"top\">64</th>\n","      <th>4</th>\n","      <td>0.715714</td>\n","      <td>0.713009</td>\n","      <td>0.767872</td>\n","      <td>0.684132</td>\n","      <td>0.650990</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.751786</td>\n","      <td>0.747351</td>\n","      <td>0.795616</td>\n","      <td>0.718134</td>\n","      <td>0.564350</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.765714</td>\n","      <td>0.766917</td>\n","      <td>0.834079</td>\n","      <td>0.724512</td>\n","      <td>0.454914</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.761429</td>\n","      <td>0.752455</td>\n","      <td>0.796083</td>\n","      <td>0.735550</td>\n","      <td>0.365019</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.761071</td>\n","      <td>0.768538</td>\n","      <td>0.854733</td>\n","      <td>0.709530</td>\n","      <td>0.311527</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>96 rows × 5 columns</p>\n","</div>"],"text/plain":["                                 accuracy        f1  ...  precision      loss\n","EnglishBert hidden 0.00002 32 1  0.632500  0.517751  ...   0.686184  0.718207\n","                              2  0.727500  0.728819  ...   0.694697  0.611783\n","                              3  0.760357  0.738647  ...   0.754953  0.504368\n","                              4  0.777500  0.772462  ...   0.744135  0.400660\n","                              5  0.777143  0.757069  ...   0.778056  0.284866\n","...                                   ...       ...  ...        ...       ...\n","            pooler 0.00005 64 4  0.715714  0.713009  ...   0.684132  0.650990\n","                              5  0.751786  0.747351  ...   0.718134  0.564350\n","                              6  0.765714  0.766917  ...   0.724512  0.454914\n","                              7  0.761429  0.752455  ...   0.735550  0.365019\n","                              8  0.761071  0.768538  ...   0.709530  0.311527\n","\n","[96 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"r7M8o_lHjzkC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619288907553,"user_tz":180,"elapsed":553,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"367e118c-8f3c-4bb9-fe94-f2892ef01145"},"source":["## Creating LateX Table\n","LabelTaskTable = FileResults\n","print(DfResultsTask.to_latex(multicolumn=True, multirow=False, label=LabelTaskTable))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\\begin{table}\n","\\centering\n","\\label{EnglishBertTask1enDataTrain_Results}\n","\\begin{tabular}{lllllrrrrr}\n","\\toprule\n","            &        &         &    &   &  accuracy &        f1 &    recall &  precision &      loss \\\\\n","\\midrule\n","EnglishBert & hidden & 0.00002 & 32 & 1 &  0.632500 &  0.517751 &  0.459445 &   0.686184 &  0.718207 \\\\\n","            &        &         &    & 2 &  0.727500 &  0.728819 &  0.791426 &   0.694697 &  0.611783 \\\\\n","            &        &         &    & 3 &  0.760357 &  0.738647 &  0.739083 &   0.754953 &  0.504368 \\\\\n","            &        &         &    & 4 &  0.777500 &  0.772462 &  0.817220 &   0.744135 &  0.400660 \\\\\n","            &        &         &    & 5 &  0.777143 &  0.757069 &  0.755135 &   0.778056 &  0.284866 \\\\\n","            &        &         &    & 6 &  0.777500 &  0.756750 &  0.750585 &   0.776875 &  0.200690 \\\\\n","            &        &         &    & 7 &  0.771786 &  0.750785 &  0.742667 &   0.774955 &  0.136298 \\\\\n","            &        &         &    & 8 &  0.771071 &  0.768477 &  0.816745 &   0.740808 &  0.089574 \\\\\n","            &        &         & 64 & 1 &  0.543929 &  0.527811 &  0.699977 &   0.528341 &  0.712645 \\\\\n","            &        &         &    & 2 &  0.637143 &  0.523399 &  0.488817 &   0.677361 &  0.677493 \\\\\n","            &        &         &    & 3 &  0.681071 &  0.692402 &  0.783707 &   0.643811 &  0.628188 \\\\\n","            &        &         &    & 4 &  0.720714 &  0.711035 &  0.743839 &   0.693866 &  0.577761 \\\\\n","            &        &         &    & 5 &  0.740357 &  0.734686 &  0.773005 &   0.712371 &  0.522633 \\\\\n","            &        &         &    & 6 &  0.749643 &  0.739200 &  0.766652 &   0.726751 &  0.460832 \\\\\n","            &        &         &    & 7 &  0.758571 &  0.758235 &  0.811874 &   0.720436 &  0.416831 \\\\\n","            &        &         &    & 8 &  0.768929 &  0.760294 &  0.787948 &   0.745353 &  0.373757 \\\\\n","            &        & 0.00003 & 32 & 1 &  0.652500 &  0.585391 &  0.597713 &   0.668485 &  0.718207 \\\\\n","            &        &         &    & 2 &  0.742143 &  0.736306 &  0.774261 &   0.718130 &  0.595456 \\\\\n","            &        &         &    & 3 &  0.773214 &  0.756826 &  0.771308 &   0.765053 &  0.462896 \\\\\n","            &        &         &    & 4 &  0.780357 &  0.763025 &  0.768017 &   0.774038 &  0.335329 \\\\\n","            &        &         &    & 5 &  0.781786 &  0.767607 &  0.787575 &   0.763943 &  0.209806 \\\\\n","            &        &         &    & 6 &  0.771429 &  0.752797 &  0.751868 &   0.768300 &  0.123263 \\\\\n","            &        &         &    & 7 &  0.772857 &  0.760645 &  0.778140 &   0.759311 &  0.059705 \\\\\n","            &        &         &    & 8 &  0.765357 &  0.765611 &  0.828051 &   0.726475 &  0.037029 \\\\\n","            &        &         & 64 & 1 &  0.557143 &  0.525162 &  0.623200 &   0.575665 &  0.712645 \\\\\n","            &        &         &    & 2 &  0.637500 &  0.518773 &  0.526907 &   0.662866 &  0.665036 \\\\\n","            &        &         &    & 3 &  0.688929 &  0.699800 &  0.791728 &   0.664264 &  0.615969 \\\\\n","            &        &         &    & 4 &  0.733929 &  0.719635 &  0.740934 &   0.717711 &  0.549136 \\\\\n","            &        &         &    & 5 &  0.743571 &  0.728363 &  0.743438 &   0.732801 &  0.486442 \\\\\n","            &        &         &    & 6 &  0.762857 &  0.755631 &  0.792299 &   0.736952 &  0.425104 \\\\\n","            &        &         &    & 7 &  0.768571 &  0.763437 &  0.808272 &   0.733650 &  0.354657 \\\\\n","            &        &         &    & 8 &  0.769286 &  0.761238 &  0.792729 &   0.744587 &  0.304435 \\\\\n","            &        & 0.00005 & 32 & 1 &  0.644643 &  0.579351 &  0.637358 &   0.664830 &  0.718207 \\\\\n","            &        &         &    & 2 &  0.745000 &  0.738949 &  0.785501 &   0.719311 &  0.607532 \\\\\n","            &        &         &    & 3 &  0.769286 &  0.753568 &  0.763180 &   0.759317 &  0.452252 \\\\\n","            &        &         &    & 4 &  0.756071 &  0.723075 &  0.707801 &   0.786267 &  0.293778 \\\\\n","            &        &         &    & 5 &  0.766786 &  0.746508 &  0.755126 &   0.765102 &  0.189886 \\\\\n","            &        &         &    & 6 &  0.763214 &  0.751389 &  0.784669 &   0.740630 &  0.105226 \\\\\n","            &        &         &    & 7 &  0.768571 &  0.763882 &  0.816270 &   0.733245 &  0.057261 \\\\\n","            &        &         &    & 8 &  0.765357 &  0.761581 &  0.812537 &   0.728369 &  0.030155 \\\\\n","            &        &         & 64 & 1 &  0.560714 &  0.429671 &  0.514154 &   0.499152 &  0.712645 \\\\\n","            &        &         &    & 2 &  0.637143 &  0.543231 &  0.591437 &   0.664482 &  0.666076 \\\\\n","            &        &         &    & 3 &  0.689643 &  0.706994 &  0.802909 &   0.659395 &  0.625417 \\\\\n","            &        &         &    & 4 &  0.733214 &  0.720282 &  0.751448 &   0.720074 &  0.550142 \\\\\n","            &        &         &    & 5 &  0.763214 &  0.752276 &  0.779964 &   0.740016 &  0.478089 \\\\\n","            &        &         &    & 6 &  0.770000 &  0.756729 &  0.775279 &   0.753287 &  0.387465 \\\\\n","            &        &         &    & 7 &  0.773929 &  0.766351 &  0.803124 &   0.746626 &  0.321695 \\\\\n","            &        &         &    & 8 &  0.780357 &  0.773331 &  0.812360 &   0.747310 &  0.254721 \\\\\n","            & pooler & 0.00002 & 32 & 1 &  0.593214 &  0.462162 &  0.456717 &   0.612894 &  0.744179 \\\\\n","            &        &         &    & 2 &  0.701786 &  0.688504 &  0.719707 &   0.684894 &  0.674682 \\\\\n","            &        &         &    & 3 &  0.747857 &  0.750568 &  0.820353 &   0.704953 &  0.574068 \\\\\n","            &        &         &    & 4 &  0.762143 &  0.752959 &  0.790099 &   0.736059 &  0.430827 \\\\\n","            &        &         &    & 5 &  0.773214 &  0.761348 &  0.786937 &   0.753319 &  0.310749 \\\\\n","            &        &         &    & 6 &  0.768214 &  0.755164 &  0.771509 &   0.753137 &  0.221113 \\\\\n","            &        &         &    & 7 &  0.767857 &  0.754017 &  0.768538 &   0.758056 &  0.144855 \\\\\n","            &        &         &    & 8 &  0.768214 &  0.767164 &  0.822844 &   0.729242 &  0.113949 \\\\\n","            &        &         & 64 & 1 &  0.555357 &  0.563351 &  0.628195 &   0.530917 &  0.734696 \\\\\n","            &        &         &    & 2 &  0.592143 &  0.417865 &  0.342705 &   0.624742 &  0.696542 \\\\\n","            &        &         &    & 3 &  0.667857 &  0.592893 &  0.540777 &   0.698047 &  0.679938 \\\\\n","            &        &         &    & 4 &  0.697143 &  0.716070 &  0.818209 &   0.648860 &  0.649879 \\\\\n","            &        &         &    & 5 &  0.721071 &  0.710926 &  0.740162 &   0.697172 &  0.593943 \\\\\n","            &        &         &    & 6 &  0.734286 &  0.717362 &  0.732099 &   0.715957 &  0.519449 \\\\\n","            &        &         &    & 7 &  0.750357 &  0.748069 &  0.802089 &   0.710191 &  0.461962 \\\\\n","            &        &         &    & 8 &  0.749286 &  0.742938 &  0.783177 &   0.716142 &  0.396341 \\\\\n","            &        & 0.00003 & 32 & 1 &  0.556786 &  0.158760 &  0.118064 &   0.416141 &  0.744179 \\\\\n","            &        &         &    & 2 &  0.719643 &  0.688824 &  0.678148 &   0.724853 &  0.680667 \\\\\n","            &        &         &    & 3 &  0.755000 &  0.745173 &  0.787599 &   0.735322 &  0.569800 \\\\\n","            &        &         &    & 4 &  0.772143 &  0.756095 &  0.775118 &   0.758703 &  0.431745 \\\\\n","            &        &         &    & 5 &  0.759286 &  0.739368 &  0.741484 &   0.760229 &  0.285094 \\\\\n","            &        &         &    & 6 &  0.755000 &  0.731854 &  0.727842 &   0.756109 &  0.174532 \\\\\n","            &        &         &    & 7 &  0.764286 &  0.758503 &  0.803273 &   0.733831 &  0.096136 \\\\\n","            &        &         &    & 8 &  0.760714 &  0.761620 &  0.828238 &   0.717752 &  0.080402 \\\\\n","            &        &         & 64 & 1 &  0.522143 &  0.598838 &  0.781034 &   0.505668 &  0.734696 \\\\\n","            &        &         &    & 2 &  0.562143 &  0.208193 &  0.138796 &   0.584983 &  0.702680 \\\\\n","            &        &         &    & 3 &  0.661786 &  0.648666 &  0.691080 &   0.647681 &  0.689454 \\\\\n","            &        &         &    & 4 &  0.690000 &  0.707951 &  0.814521 &   0.644741 &  0.664924 \\\\\n","            &        &         &    & 5 &  0.730000 &  0.723010 &  0.761654 &   0.701280 &  0.614116 \\\\\n","            &        &         &    & 6 &  0.748571 &  0.736579 &  0.760215 &   0.728610 &  0.524116 \\\\\n","            &        &         &    & 7 &  0.750000 &  0.734066 &  0.746562 &   0.735385 &  0.446630 \\\\\n","            &        &         &    & 8 &  0.762143 &  0.757607 &  0.802651 &   0.728667 &  0.373082 \\\\\n","            &        & 0.00005 & 32 & 1 &  0.553571 &  0.147707 &  0.131976 &   0.248279 &  0.744179 \\\\\n","            &        &         &    & 2 &  0.712143 &  0.680376 &  0.693402 &   0.716218 &  0.691405 \\\\\n","            &        &         &    & 3 &  0.761071 &  0.763274 &  0.836092 &   0.713758 &  0.576522 \\\\\n","            &        &         &    & 4 &  0.761786 &  0.746916 &  0.769447 &   0.752352 &  0.404779 \\\\\n","            &        &         &    & 5 &  0.761786 &  0.741466 &  0.744117 &   0.758667 &  0.293504 \\\\\n","            &        &         &    & 6 &  0.765714 &  0.752660 &  0.775019 &   0.749359 &  0.174349 \\\\\n","            &        &         &    & 7 &  0.762857 &  0.762946 &  0.828164 &   0.722230 &  0.090528 \\\\\n","            &        &         &    & 8 &  0.770714 &  0.763670 &  0.797148 &   0.745426 &  0.064481 \\\\\n","            &        &         & 64 & 1 &  0.501071 &  0.584592 &  0.804264 &   0.486496 &  0.734696 \\\\\n","            &        &         &    & 2 &  0.551429 &  0.150175 &  0.104262 &   0.348348 &  0.707329 \\\\\n","            &        &         &    & 3 &  0.685000 &  0.691453 &  0.765777 &   0.649914 &  0.690112 \\\\\n","            &        &         &    & 4 &  0.715714 &  0.713009 &  0.767872 &   0.684132 &  0.650990 \\\\\n","            &        &         &    & 5 &  0.751786 &  0.747351 &  0.795616 &   0.718134 &  0.564350 \\\\\n","            &        &         &    & 6 &  0.765714 &  0.766917 &  0.834079 &   0.724512 &  0.454914 \\\\\n","            &        &         &    & 7 &  0.761429 &  0.752455 &  0.796083 &   0.735550 &  0.365019 \\\\\n","            &        &         &    & 8 &  0.761071 &  0.768538 &  0.854733 &   0.709530 &  0.311527 \\\\\n","\\bottomrule\n","\\end{tabular}\n","\\end{table}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pR_Zy_eIcl2i"},"source":["# Inference"]},{"cell_type":"markdown","metadata":{"id":"Hx8CXkIr3NuW"},"source":["##Train the model with Full Train dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"suGc2RmyuPzk","executionInfo":{"status":"ok","timestamp":1619288911230,"user_tz":180,"elapsed":540,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"f9462a5a-1915-4eb3-8234-e5dbd6af7a43"},"source":["## 10 Best resuts\n","MetricForBestResults = 'f1' if df_train['Label'].nunique() > 2 else 'accuracy'\n","DfResultsTask.nlargest(n=10, columns= MetricForBestResults )"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>recall</th>\n","      <th>precision</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"10\" valign=\"top\">EnglishBert</th>\n","      <th rowspan=\"7\" valign=\"top\">hidden</th>\n","      <th rowspan=\"2\" valign=\"top\">0.00003</th>\n","      <th rowspan=\"2\" valign=\"top\">32</th>\n","      <th>5</th>\n","      <td>0.781786</td>\n","      <td>0.767607</td>\n","      <td>0.787575</td>\n","      <td>0.763943</td>\n","      <td>0.209806</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.780357</td>\n","      <td>0.763025</td>\n","      <td>0.768017</td>\n","      <td>0.774038</td>\n","      <td>0.335329</td>\n","    </tr>\n","    <tr>\n","      <th>0.00005</th>\n","      <th>64</th>\n","      <th>8</th>\n","      <td>0.780357</td>\n","      <td>0.773331</td>\n","      <td>0.812360</td>\n","      <td>0.747310</td>\n","      <td>0.254721</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">0.00002</th>\n","      <th rowspan=\"3\" valign=\"top\">32</th>\n","      <th>4</th>\n","      <td>0.777500</td>\n","      <td>0.772462</td>\n","      <td>0.817220</td>\n","      <td>0.744135</td>\n","      <td>0.400660</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.777500</td>\n","      <td>0.756750</td>\n","      <td>0.750585</td>\n","      <td>0.776875</td>\n","      <td>0.200690</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.777143</td>\n","      <td>0.757069</td>\n","      <td>0.755135</td>\n","      <td>0.778056</td>\n","      <td>0.284866</td>\n","    </tr>\n","    <tr>\n","      <th>0.00005</th>\n","      <th>64</th>\n","      <th>7</th>\n","      <td>0.773929</td>\n","      <td>0.766351</td>\n","      <td>0.803124</td>\n","      <td>0.746626</td>\n","      <td>0.321695</td>\n","    </tr>\n","    <tr>\n","      <th>pooler</th>\n","      <th>0.00002</th>\n","      <th>32</th>\n","      <th>5</th>\n","      <td>0.773214</td>\n","      <td>0.761348</td>\n","      <td>0.786937</td>\n","      <td>0.753319</td>\n","      <td>0.310749</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">hidden</th>\n","      <th rowspan=\"2\" valign=\"top\">0.00003</th>\n","      <th rowspan=\"2\" valign=\"top\">32</th>\n","      <th>3</th>\n","      <td>0.773214</td>\n","      <td>0.756826</td>\n","      <td>0.771308</td>\n","      <td>0.765053</td>\n","      <td>0.462896</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.772857</td>\n","      <td>0.760645</td>\n","      <td>0.778140</td>\n","      <td>0.759311</td>\n","      <td>0.059705</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 accuracy        f1  ...  precision      loss\n","EnglishBert hidden 0.00003 32 5  0.781786  0.767607  ...   0.763943  0.209806\n","                              4  0.780357  0.763025  ...   0.774038  0.335329\n","                   0.00005 64 8  0.780357  0.773331  ...   0.747310  0.254721\n","                   0.00002 32 4  0.777500  0.772462  ...   0.744135  0.400660\n","                              6  0.777500  0.756750  ...   0.776875  0.200690\n","                              5  0.777143  0.757069  ...   0.778056  0.284866\n","                   0.00005 64 7  0.773929  0.766351  ...   0.746626  0.321695\n","            pooler 0.00002 32 5  0.773214  0.761348  ...   0.753319  0.310749\n","            hidden 0.00003 32 3  0.773214  0.756826  ...   0.765053  0.462896\n","                              7  0.772857  0.760645  ...   0.759311  0.059705\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9Dh28hHvWw8","executionInfo":{"status":"ok","timestamp":1619288914119,"user_tz":180,"elapsed":588,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"34c5aa68-5d5a-4187-a397-035fe1f2bac4"},"source":["## Get best parameters from cross-validation DataFrame \n","BestResultParameters = DfResultsTask.sort_values(MetricForBestResults, ascending=False)[:1].index\n","print(f'Best parameters : {BestResultParameters}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Best parameters : MultiIndex([('EnglishBert', 'hidden', 3e-05, 32, 5)],\n","           )\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-2gzpiLswJOL"},"source":["## Add best parameters to variables in the final train\n","BertPath = BertVersion[BestResultParameters[0][0]]\n","BertVersion = {BestResultParameters[0][0] : BertVersion[BestResultParameters[0][0]]}\n","OutputBert = [BestResultParameters[0][1]]\n","LearningRate = [float(BestResultParameters[0][2])]\n","BatchSize = [int(BestResultParameters[0][3])]\n","Epochs = int(BestResultParameters[0][4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8BPtlIz7ZXW"},"source":["## Criate dictinaril results\n","ResultsTaskBestParameters = { bert:{ output:{ lr:{ bat:{ epoc:{ metric:[] for metric in Metrics + ['loss']} for epoc in range(1, Epochs+1) } for bat in BatchSize} for lr in LearningRate} for output in OutputBert } for bert in BertVersion.keys() }\n","\n","## Create file to save results BEST Parameters\n","#### Create file name\n","FileResultsBestModel = FileResults + 'BestModel'\n","#### Save the file fro results BEST Parameters\n","with open(Path + FileResultsBestModel + \".pkl\",'wb') as f:\n","  pickle.dump(ResultsTaskBestParameters, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"id":"U7e2YUAfxufW","executionInfo":{"status":"error","timestamp":1619288991682,"user_tz":180,"elapsed":3035,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"85d60c0b-aa97-44c2-dceb-9e7b7de613dc"},"source":["## Train with Best parameters\n","\n","## Best parameters\n","BertV = BestResultParameters[0][0]\n","BertPath = BertVersion[BestResultParameters[0][0]]\n","OutputB = OutputBert[0]\n","lr = LearningRate[0]\n","Batch = BatchSize[0]\n","Epochs = Epochs\n","\n","### Loading Bert trained weights\n","mx = BERTBaseUncased(bert_path=BertPath, output_bert=OutputB, NumberOfClasses=df_train['Label'].nunique())\n","\n","## Split train and test\n","X_train = df_train['Data']\n","y_train = df_train['Label']\n","_, X_test, _, y_test = train_test_split(df_train['Data'], df_train['Label'], test_size=0.33, random_state=42)\n","\n","print(f'parameters: Bertmodel: {BertV}, Output: {OutputB}, lr: {lr}, Batch: {Batch}, Totsl Num. Epochs: {Epochs}')\n","MoDeL = TrainModel(PathSaveFiles = Path,\n","                  BertVersion=BertV,\n","                  BertPath=BertPath,\n","                  OutputBert=OutputB,\n","                  LearningRate=lr,\n","                  BatchSize=Batch,\n","                  Epochs=Epochs,\n","                  FileName= FileResultsBestModel,\n","                  X_train=X_train, \n","                  X_valid=X_test,\n","                  y_train=y_train,\n","                  y_valid=y_test,\n","                  SaveModel=True)\n","\n","\n","def _mp_fn(rank, flags):\n","  torch.set_default_tensor_type('torch.FloatTensor')\n","  a = MoDeL._run()\n","\n","FLAGS={}\n","xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["parameters: Bertmodel: EnglishBert, Output: hidden, lr: 3e-05, Batch: 32, Totsl Num. Epochs: 5\n"],"name":"stdout"},{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-1d0c64518ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n-- Process %d terminated with the following error:\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moriginal_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 225, in _start_fn\n    _setup_replication()\n  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 218, in _setup_replication\n    xm.set_replication(str(device), [str(device)])\n  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 217, in set_replication\n    replication_devices = xla_replication_devices(devices)\n  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 204, in xla_replication_devices\n    format(len(local_devices), len(kind_devices)))\nRuntimeError: Cannot replicate if number of devices (1) is different from 8\n"]}]},{"cell_type":"code","metadata":{"id":"kC7Qio7rfXpM"},"source":["## Average and Save Results\n","AverageResultsTaskBestModel = AveragResults(FileName=FileResultsBestModel, Path=Path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"1sjtPlRWfhOU","executionInfo":{"status":"ok","timestamp":1619268975298,"user_tz":180,"elapsed":496,"user":{"displayName":"Marieli Lauxen","photoUrl":"","userId":"02046508060582016885"}},"outputId":"e7551d7d-dc05-4238-b721-659bb9bd3627"},"source":["## Create a Data Frame\n","DfResultsTaskBestModel = create_Data_Frame(all_resultas=AverageResultsTaskBestModel)\n","\n","### save results to a CSV file\n","DfResultsTaskBestModel.to_csv(Path + 'Average' + FileResultsBestModel + '_CSV_' + '.csv')\n","\n","### See the Avarage results in the Pandas data Frame\n","DfResultsTaskBestModel"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>recall</th>\n","      <th>precision</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">EnglishBert</th>\n","      <th rowspan=\"5\" valign=\"top\">hidden</th>\n","      <th rowspan=\"5\" valign=\"top\">0.00003</th>\n","      <th rowspan=\"5\" valign=\"top\">32</th>\n","      <th>1</th>\n","      <td>0.608553</td>\n","      <td>0.237622</td>\n","      <td>0.135417</td>\n","      <td>1.000000</td>\n","      <td>0.829413</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.805921</td>\n","      <td>0.779498</td>\n","      <td>0.758457</td>\n","      <td>0.805057</td>\n","      <td>0.630450</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.836623</td>\n","      <td>0.829182</td>\n","      <td>0.873791</td>\n","      <td>0.790378</td>\n","      <td>0.542547</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.895833</td>\n","      <td>0.886149</td>\n","      <td>0.900453</td>\n","      <td>0.873260</td>\n","      <td>0.458032</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.905702</td>\n","      <td>0.897724</td>\n","      <td>0.917757</td>\n","      <td>0.879712</td>\n","      <td>0.349698</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 accuracy        f1  ...  precision      loss\n","EnglishBert hidden 0.00003 32 1  0.608553  0.237622  ...   1.000000  0.829413\n","                              2  0.805921  0.779498  ...   0.805057  0.630450\n","                              3  0.836623  0.829182  ...   0.790378  0.542547\n","                              4  0.895833  0.886149  ...   0.873260  0.458032\n","                              5  0.905702  0.897724  ...   0.879712  0.349698\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"Ga0vMmCcDB8o"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"hXCgZxJIDvId"},"source":["class BERTDatasetTest:\n","    def __init__(self, comment_text, tokenizer, max_length):\n","        self.comment_text = comment_text\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, item):\n","        comment_text = str(self.comment_text[item])\n","        comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","        )\n","        ids = inputs[\"input_ids\"]\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        \n","        padding_length = self.max_length - len(ids)\n","        \n","        ids = ids + ([0] * padding_length)\n","        mask = mask + ([0] * padding_length)\n","        token_type_ids = token_type_ids + ([0] * padding_length)\n","        \n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQW-3pCYDvIf"},"source":["## Bert tozenizer\n","tokenizer = transformers.BertTokenizer.from_pretrained(BertPath, do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_oKhH6SDvIf","executionInfo":{"status":"ok","timestamp":1619289083571,"user_tz":180,"elapsed":15940,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"6a00b6f3-e0c3-4709-e251-e4c68133463b"},"source":["## Loading the best model\n","device = torch.device(\"xla\")\n","model = BERTBaseUncased(bert_path=BertPath, output_bert=OutputB, NumberOfClasses=df_train['Label'].nunique()).to(device)\n","FileBestModel = Path + FileResultsBestModel + '.bin'\n","model.load_state_dict(torch.load(FileBestModel))\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERTBaseUncased(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert_drop): Dropout(p=0.3, inplace=False)\n","  (OutPutHidden): Linear(in_features=1536, out_features=2, bias=True)\n","  (OutPoller): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"O2Fj1aIFEs-k"},"source":["### Test Whole Data"]},{"cell_type":"code","metadata":{"id":"Hq25wBkgy2KG"},"source":["## Prepresing the data\n","valid_dataset = BERTDatasetTest(\n","        comment_text=df_test_whole['Data'].values,\n","        tokenizer=tokenizer,\n","        max_length=110\n",")\n","\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=Batch,\n","    drop_last=False,\n","    num_workers=4,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DVa0m3uy2KN","executionInfo":{"status":"ok","timestamp":1619289104284,"user_tz":180,"elapsed":11708,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"a89ee787-b346-464a-f1bd-c3c9ff7663a9"},"source":["## Making the Inferences\n","with torch.no_grad():\n","    fin_outputs = []\n","    for bi, d in tqdm(enumerate(valid_data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_np = outputs.detach().cpu().numpy().tolist()\n","        fin_outputs.extend(outputs_np) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["44it [00:11,  3.98it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"1CUvjwivy2KO","executionInfo":{"status":"ok","timestamp":1619289110660,"user_tz":180,"elapsed":533,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"75c56ce8-fb66-4207-9379-e303b33526ec"},"source":["## List with Results\n","fin_outputs\n","\n","## create a Dataframe from List of Results\n","df_results = pd.DataFrame.from_records(fin_outputs)\n","\n","## change columns if task2\n","if df_train['Label'].nunique() > 2:\n","  df_results = df_results.rename({0:1, 1:2, 2:3, 3:4, 4:5}, axis='columns')\n","\n","## get the model inference\n","df_results['Inference'] = df_results.idxmax(axis=1)\n","\n","## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.944694</td>\n","      <td>-2.095059</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.419009</td>\n","      <td>-1.424598</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.470887</td>\n","      <td>-1.131224</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.565983</td>\n","      <td>-0.345339</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.671665</td>\n","      <td>0.796625</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference\n","0  1.944694 -2.095059          0\n","1  1.419009 -1.424598          0\n","2  1.470887 -1.131224          0\n","3  0.565983 -0.345339          0\n","4 -0.671665  0.796625          1"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cN9_Oucsy2KO","executionInfo":{"status":"ok","timestamp":1619289116741,"user_tz":180,"elapsed":497,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"baffef25-0787-47f2-b80f-a2241886ef34"},"source":["## Get rows index\n","df_idex = df_test_whole.loc[:,[\"id\", \"Label\"]]\n","\n","## Add index to the Results dataframe\n","df_results = df_results.join(df_idex)\n","\n","### save results to a CSV file\n","df_results.to_csv(Path + 'ModelInfereneces_' + FileResultsBestModel + '_WholeSetTest' +'_CSV_' + '.csv')\n","\n","## ## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","      <th>id</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.944694</td>\n","      <td>-2.095059</td>\n","      <td>0</td>\n","      <td>4516</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.419009</td>\n","      <td>-1.424598</td>\n","      <td>0</td>\n","      <td>3573</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.470887</td>\n","      <td>-1.131224</td>\n","      <td>0</td>\n","      <td>4232</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.565983</td>\n","      <td>-0.345339</td>\n","      <td>0</td>\n","      <td>3782</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.671665</td>\n","      <td>0.796625</td>\n","      <td>1</td>\n","      <td>6357</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference    id  Label\n","0  1.944694 -2.095059          0  4516      0\n","1  1.419009 -1.424598          0  3573      0\n","2  1.470887 -1.131224          0  4232      0\n","3  0.565983 -0.345339          0  3782      0\n","4 -0.671665  0.796625          1  6357      0"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKJlJxyoy2KP","executionInfo":{"status":"ok","timestamp":1619289120345,"user_tz":180,"elapsed":507,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"59cdddd9-a119-4f57-cd9a-eb61f08d047f"},"source":["## caculation of performace metric\n","Target = df_results[df_results.columns[-1]].tolist()\n","Output = df_results[df_results.columns[-3]].tolist()\n","\n","average_metrics = 'macro' if df_train['Label'].nunique() > 2 else 'binary'\n","print(f'Accuracy : {metrics.accuracy_score(Target, Output)}')\n","print(f'Recall : {metrics.recall_score(Target, Output, average = average_metrics)}')\n","print(f'Precision : {metrics.precision_score(Target, Output, average = average_metrics)}')\n","print(f'f1-score : {metrics.f1_score(Target, Output, average= average_metrics)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy : 0.7318996415770609\n","Recall : 0.6933333333333334\n","Precision : 0.7370078740157481\n","f1-score : 0.7145038167938932\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rAUqLIz1E4KN"},"source":["### Test Only English"]},{"cell_type":"code","metadata":{"id":"26g-2-kTx-GG"},"source":["## Prepresing the data\n","valid_dataset = BERTDatasetTest(\n","        comment_text=df_test_en['Data'].values,\n","        tokenizer=tokenizer,\n","        max_length=110\n",")\n","\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=Batch,\n","    drop_last=False,\n","    num_workers=4,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tk3GR6y2x-GO","executionInfo":{"status":"ok","timestamp":1619289132015,"user_tz":180,"elapsed":6222,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"b7270ea8-79cf-41bb-8879-bb5f61f70d1b"},"source":["## Making the Inferences\n","with torch.no_grad():\n","    fin_outputs = []\n","    for bi, d in tqdm(enumerate(valid_data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_np = outputs.detach().cpu().numpy().tolist()\n","        fin_outputs.extend(outputs_np) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["22it [00:05,  3.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"d35f83mSx-GP","executionInfo":{"status":"ok","timestamp":1619289136319,"user_tz":180,"elapsed":516,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"7e7e30c2-0335-45ec-9f26-9cd152c02044"},"source":["## List with Results\n","fin_outputs\n","\n","## create a Dataframe from List of Results\n","df_results = pd.DataFrame.from_records(fin_outputs)\n","\n","## change columns if task2\n","if df_train['Label'].nunique() > 2:\n","  df_results = df_results.rename({0:1, 1:2, 2:3, 3:4, 4:5}, axis='columns')\n","\n","## get the model inference\n","df_results['Inference'] = df_results.idxmax(axis=1)\n","\n","## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.835893</td>\n","      <td>-1.964890</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.284768</td>\n","      <td>-0.076747</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.435505</td>\n","      <td>1.516354</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.074585</td>\n","      <td>-2.033102</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.449182</td>\n","      <td>-1.389517</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference\n","0  1.835893 -1.964890          0\n","1  0.284768 -0.076747          0\n","2 -1.435505  1.516354          1\n","3  2.074585 -2.033102          0\n","4  1.449182 -1.389517          0"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"gUx7dauHx-GP","executionInfo":{"status":"ok","timestamp":1619289143509,"user_tz":180,"elapsed":560,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"eaed238e-18e2-430b-b601-00af786a0522"},"source":["## Get rows index\n","df_idex = df_test_en.loc[:,[\"id\", \"Label\"]]\n","\n","## Add index to the Results dataframe\n","df_results = df_results.join(df_idex)\n","\n","### save results to a CSV file\n","df_results.to_csv(Path + 'ModelInfereneces_' + FileResultsBestModel + '_EnglishSetTest' +'_CSV_' + '.csv')\n","\n","## ## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","      <th>id</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.835893</td>\n","      <td>-1.964890</td>\n","      <td>0</td>\n","      <td>1541</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.284768</td>\n","      <td>-0.076747</td>\n","      <td>0</td>\n","      <td>176</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.435505</td>\n","      <td>1.516354</td>\n","      <td>1</td>\n","      <td>1082</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.074585</td>\n","      <td>-2.033102</td>\n","      <td>0</td>\n","      <td>451</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.449182</td>\n","      <td>-1.389517</td>\n","      <td>0</td>\n","      <td>2954</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference    id  Label\n","0  1.835893 -1.964890          0  1541      0\n","1  0.284768 -0.076747          0   176      0\n","2 -1.435505  1.516354          1  1082      0\n","3  2.074585 -2.033102          0   451      0\n","4  1.449182 -1.389517          0  2954      0"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1feSiYPx-GQ","executionInfo":{"status":"ok","timestamp":1619289147591,"user_tz":180,"elapsed":465,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"6f5273db-063a-4929-d600-0cec618617b3"},"source":["## caculation of performace metric\n","Target = df_results[df_results.columns[-1]].tolist()\n","Output = df_results[df_results.columns[-3]].tolist()\n","\n","average_metrics = 'macro' if df_train['Label'].nunique() > 2 else 'binary'\n","print(f'Accuracy : {metrics.accuracy_score(Target, Output)}')\n","print(f'Recall : {metrics.recall_score(Target, Output, average = average_metrics)}')\n","print(f'Precision : {metrics.precision_score(Target, Output, average = average_metrics)}')\n","print(f'f1-score : {metrics.f1_score(Target, Output, average= average_metrics)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy : 0.7685589519650655\n","Recall : 0.7920489296636085\n","Precision : 0.74\n","f1-score : 0.7651403249630725\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UJhi-aXBE_Q-"},"source":["### Test Only Spanish"]},{"cell_type":"code","metadata":{"id":"JqCxsxL3DvIg"},"source":["## Prepresing the data\n","valid_dataset = BERTDatasetTest(\n","        comment_text=df_test_es['Data'].values,\n","        tokenizer=tokenizer,\n","        max_length=110\n",")\n","\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=Batch,\n","    drop_last=False,\n","    num_workers=4,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrRLNlXKDvIg","executionInfo":{"status":"ok","timestamp":1619289159435,"user_tz":180,"elapsed":5014,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"663b11f3-7766-45a4-c2d1-d3d7b008c00d"},"source":["## Making the Inferences\n","with torch.no_grad():\n","    fin_outputs = []\n","    for bi, d in tqdm(enumerate(valid_data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_np = outputs.detach().cpu().numpy().tolist()\n","        fin_outputs.extend(outputs_np) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["23it [00:04,  5.20it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"BrAgWIoeDvIg","executionInfo":{"status":"ok","timestamp":1619289166728,"user_tz":180,"elapsed":535,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"f1ded2b3-c37a-415c-d90a-ae9e742b55f3"},"source":["## List with Results\n","fin_outputs\n","\n","## create a Dataframe from List of Results\n","df_results = pd.DataFrame.from_records(fin_outputs)\n","\n","## change columns if task2\n","if df_train['Label'].nunique() > 2:\n","  df_results = df_results.rename({0:1, 1:2, 2:3, 3:4, 4:5}, axis='columns')\n","\n","## get the model inference\n","df_results['Inference'] = df_results.idxmax(axis=1)\n","\n","## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.944694</td>\n","      <td>-2.095059</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.419009</td>\n","      <td>-1.424598</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.470887</td>\n","      <td>-1.131224</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.565983</td>\n","      <td>-0.345339</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.671665</td>\n","      <td>0.796625</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference\n","0  1.944694 -2.095059          0\n","1  1.419009 -1.424598          0\n","2  1.470887 -1.131224          0\n","3  0.565983 -0.345339          0\n","4 -0.671665  0.796625          1"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"r1yzaOJHDvIh","executionInfo":{"status":"ok","timestamp":1619289169675,"user_tz":180,"elapsed":631,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"7784b8bf-6713-4147-da35-97e32d77c2e7"},"source":["## Get rows index\n","df_idex = df_test_es.loc[:,[\"id\", \"Label\"]]\n","\n","## Add index to the Results dataframe\n","df_results = df_results.join(df_idex)\n","\n","### save results to a CSV file\n","df_results.to_csv(Path + 'ModelInfereneces_' + FileResultsBestModel + '_SpanishSetTest' + '_CSV_' + '.csv')\n","\n","## ## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","      <th>id</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.944694</td>\n","      <td>-2.095059</td>\n","      <td>0</td>\n","      <td>4516</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.419009</td>\n","      <td>-1.424598</td>\n","      <td>0</td>\n","      <td>3573</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.470887</td>\n","      <td>-1.131224</td>\n","      <td>0</td>\n","      <td>4232</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.565983</td>\n","      <td>-0.345339</td>\n","      <td>0</td>\n","      <td>3782</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.671665</td>\n","      <td>0.796625</td>\n","      <td>1</td>\n","      <td>6357</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference    id  Label\n","0  1.944694 -2.095059          0  4516      0\n","1  1.419009 -1.424598          0  3573      0\n","2  1.470887 -1.131224          0  4232      0\n","3  0.565983 -0.345339          0  3782      0\n","4 -0.671665  0.796625          1  6357      0"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GvUteMecd0V","executionInfo":{"status":"ok","timestamp":1619289172357,"user_tz":180,"elapsed":516,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"97b96e65-dab3-4343-9cbb-9c057a5c9f5a"},"source":["## caculation of performace metric\n","Target = df_results[df_results.columns[-1]].tolist()\n","Output = df_results[df_results.columns[-3]].tolist()\n","\n","average_metrics = 'macro' if df_train['Label'].nunique() > 2 else 'binary'\n","print(f'Accuracy : {metrics.accuracy_score(Target, Output)}')\n","print(f'Recall : {metrics.recall_score(Target, Output, average = average_metrics)}')\n","print(f'Precision : {metrics.precision_score(Target, Output, average = average_metrics)}')\n","print(f'f1-score : {metrics.f1_score(Target, Output, average= average_metrics)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy : 0.6963276836158192\n","Recall : 0.6005747126436781\n","Precision : 0.7333333333333333\n","f1-score : 0.660347551342812\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Iei-0sLc3QRI"},"source":["## Inference"]},{"cell_type":"markdown","metadata":{"id":"TdgiDIeC4XbB"},"source":["###Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"H3_Vpd9V4KCl","executionInfo":{"status":"ok","timestamp":1619289258303,"user_tz":180,"elapsed":1296,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"d22f28f5-5b6e-47f2-a045-b17b22ce44eb"},"source":["# Load data for inference \n","\n","#### Data Path\n","PathDataSet = '../content/drive/MyDrive/Code/EXITS/Data/'\n","FileDataset = 'EXIST2021_translatedTest'\n","#### Load tsv as a Data Frame\n","df_RealData = pd.read_csv(PathDataSet + FileDataset + '.csv', index_col=0)\n","\n","#### Change columns names for the train\n","df_RealData = df_RealData.rename(columns=NewColumnsNames)\n","\n","#### Vizualise Data\n","df_RealData.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_case</th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>text</th>\n","      <th>Data</th>\n","      <th>Spanish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021</td>\n","      <td>6978</td>\n","      <td>gab</td>\n","      <td>en</td>\n","      <td>Pennsylvania State Rep horrifies with opening ...</td>\n","      <td>Pennsylvania State Rep horrifies with opening ...</td>\n","      <td>La representante del estado de Pensilvania se ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021</td>\n","      <td>6979</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@iilovegrapes He sounds like as ass, and very ...</td>\n","      <td>@iilovegrapes He sounds like as ass, and very ...</td>\n","      <td>@iilovegrapes Suena como un idiota, y muy cond...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021</td>\n","      <td>6980</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@averyangryskel1 @4ARealistParty LOL! \"This be...</td>\n","      <td>@averyangryskel1 @4ARealistParty LOL! \"This be...</td>\n","      <td>@ averyangryskel1 @ 4ARealistParty ¡LOL! \"¡Est...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021</td>\n","      <td>6981</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>@WanderOrange @stalliontwink Rights?I mean yea...</td>\n","      <td>@WanderOrange @stalliontwink Rights?I mean yea...</td>\n","      <td>@WanderOrange @stalliontwink ¿Derechos? Quiero...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EXIST2021</td>\n","      <td>6982</td>\n","      <td>twitter</td>\n","      <td>en</td>\n","      <td>the jack manifold appreciation i’m seeing is o...</td>\n","      <td>the jack manifold appreciation i’m seeing is o...</td>\n","      <td>la apreciación de jack manifold que estoy vien...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_case  ...                                            Spanish\n","0  EXIST2021  ...  La representante del estado de Pensilvania se ...\n","1  EXIST2021  ...  @iilovegrapes Suena como un idiota, y muy cond...\n","2  EXIST2021  ...  @ averyangryskel1 @ 4ARealistParty ¡LOL! \"¡Est...\n","3  EXIST2021  ...  @WanderOrange @stalliontwink ¿Derechos? Quiero...\n","4  EXIST2021  ...  la apreciación de jack manifold que estoy vien...\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"fZwzG9CD3De_"},"source":["## Prepresing the data\n","valid_dataset = BERTDatasetTest(\n","        comment_text=df_RealData['Data'].values,\n","        tokenizer=tokenizer,\n","        max_length=110\n",")\n","\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=Batch,\n","    drop_last=False,\n","    num_workers=4,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2r70_1m-3Dhh","executionInfo":{"status":"ok","timestamp":1619289282134,"user_tz":180,"elapsed":14731,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"fb0d7ead-0903-49ea-befb-06932501b43d"},"source":["## Making the Inferences\n","with torch.no_grad():\n","    fin_outputs = []\n","    for bi, d in tqdm(enumerate(valid_data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","\n","        outputs_np = outputs.detach().cpu().numpy().tolist()\n","        fin_outputs.extend(outputs_np) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["137it [00:14,  9.69it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"03CDyHmw5ctO","executionInfo":{"status":"ok","timestamp":1619289286099,"user_tz":180,"elapsed":613,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"5caae504-148a-490f-80d5-1275debd7803"},"source":["## List with Results\n","fin_outputs\n","\n","## create a Dataframe from List of Results\n","df_results = pd.DataFrame.from_records(fin_outputs)\n","\n","## change columns if task2\n","if df_train['Label'].nunique() > 2:\n","  df_results = df_results.rename({0:1, 1:2, 2:3, 3:4, 4:5}, axis='columns')\n","\n","## get the model inference\n","df_results['Inference'] = df_results.idxmax(axis=1)\n","\n","## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.295872</td>\n","      <td>-1.186037</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.835166</td>\n","      <td>-0.908593</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.607499</td>\n","      <td>1.858016</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.430777</td>\n","      <td>1.007864</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.083438</td>\n","      <td>-2.189569</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference\n","0  1.295872 -1.186037          0\n","1  0.835166 -0.908593          0\n","2 -1.607499  1.858016          1\n","3 -0.430777  1.007864          1\n","4  2.083438 -2.189569          0"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"ELdRWwCF5cwG","executionInfo":{"status":"ok","timestamp":1619289289527,"user_tz":180,"elapsed":500,"user":{"displayName":"Angel Felipe Magnossão de Paula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH_wFI1gQCBAL2qZw2jyZm5Oys0n0a_3m48vo=s64","userId":"01261253671233798051"}},"outputId":"1c1ad5c2-ca04-40db-9364-de23d2b8d6ad"},"source":["## Get rows index\n","df_idex = df_RealData.loc[:,[\"id\"]]\n","\n","## Add index to the Results dataframe\n","df_results = df_results.join(df_idex)\n","\n","### save results to a CSV file\n","df_results.to_csv(Path + 'ModelInfereneces' + FileResultsBestModel + '_RealData' + '_CSV_' + '.csv')\n","\n","## ## Visualize results\n","df_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>Inference</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.295872</td>\n","      <td>-1.186037</td>\n","      <td>0</td>\n","      <td>6978</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.835166</td>\n","      <td>-0.908593</td>\n","      <td>0</td>\n","      <td>6979</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.607499</td>\n","      <td>1.858016</td>\n","      <td>1</td>\n","      <td>6980</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.430777</td>\n","      <td>1.007864</td>\n","      <td>1</td>\n","      <td>6981</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.083438</td>\n","      <td>-2.189569</td>\n","      <td>0</td>\n","      <td>6982</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1  Inference    id\n","0  1.295872 -1.186037          0  6978\n","1  0.835166 -0.908593          0  6979\n","2 -1.607499  1.858016          1  6980\n","3 -0.430777  1.007864          1  6981\n","4  2.083438 -2.189569          0  6982"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"wAAfHs5FZd7Q"},"source":["#Task2 - Multiclass"]},{"cell_type":"markdown","metadata":{"id":"ZexzKD0k8nN5"},"source":["# Util when the process stops sandly"]},{"cell_type":"code","metadata":{"id":"EyR_w29Jl71U"},"source":["# import pickle\n","# with open('drive/MyDrive/Code/EXITS/Machine-Learning-Tweets-Classification/Bert/Results/EnglishBert_enDataTrain/EnglishBertTask1enDataTrain_Results' + \".pkl\", \"rb\") as f:\n","#   Re = pickle.load(f)\n","# Re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_cMxNLrju5x"},"source":["# DfResultsTask = pd.read_csv(Path + 'AverageSpanishBertTask1Results_CSV_.csv', index_col=[0,1], skipinitialspace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n-eBqL2fl1Ci"},"source":["# def CleanBrokeTrain(FileName, Path, NumberOfFoldes=10):\n","#   with open(Path + FileName + \".pkl\", \"rb\") as f:\n","#               Results = pickle.load(f)\n","\n","#   for BT, ModelBertType,  in Results.items():\n","#     for OP, OutPut in ModelBertType.items():\n","#       for LR, LearningRate in OutPut.items():\n","#         for BS, BatchSize in LearningRate.items():\n","#           for EP, Epoch in BatchSize.items():\n","#             for Metrics, ValuesCrossValidation in  Epoch.items():\n"," \n","#               if len(ValuesCrossValidation) != 0 and not len(ValuesCrossValidation) == NumberOfFoldes:\n","#                 Results[BT][OP][LR][BS][EP][Metrics] = []\n","            \n","#   with open(FileName + '.pkl','wb') as f:\n","#     pickle.dump(Results, f)\n","\n","#   with open(Path + FileName + '.pkl','wb') as f:\n","#     pickle.dump(Results, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmbpB-nzzBhE"},"source":["# CleanBrokeTrain(FileName=FileResults, Path=Path, NumberOfFoldes=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-X0JZkJisdcz"},"source":["# LengPhrase = df_train['text'].str.split().str.len().tolist()\n","# LengPhrase.sort()\n","# LengPhrase[-13:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SMKMY9FsgvN"},"source":["# LengPhrase = df_RealData['text'].str.split().str.len().tolist()\n","# LengPhrase.sort()\n","\n","# LengPhrase[-50:]"],"execution_count":null,"outputs":[]}]}